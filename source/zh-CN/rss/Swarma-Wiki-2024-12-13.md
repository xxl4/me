---
title: Swarma Wiki for 2024-12-13
date: 2024-12-13 03:31:38
tags: [RSS, Swarma, Wiki, Knowledge]
author: Swarma
summary: Swarma Wiki RSS Feed
lang: zh-CN
categories: Swarma
sitemap: true
comments: true
---

# Swarma Wiki for 2024-12-13

## 计算力学
[Read more](https://wiki.swarma.org/index.php?title=%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%AD%A6&diff=40185&oldid=40171)

Updated: 2024-12-09T08:07:54Z

<p><span dir="auto"><span class="autocomment">因果态的主要性质</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月9日 (一) 08:07的版本</td>
				</tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l57">第57行：</td>
<td class="diff-lineno" colspan="2">第57行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:木星大红斑.png|右|无框|225x225px]]</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:木星大红斑.png|右|无框|225x225px]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>预测等价性（predictive equivalence）是计算内在涌现（简称内在计算，intrinsic computation）的核心思想&lt;ref&gt;Rupe, A., &amp; Crutchfield, J. P. (2024). On principles of emergent organization. ''Physics Reports''.&lt;nowiki&gt;https://doi.org/10.1016/j.physlet.2024.06.017&lt;/nowiki&gt;&lt;/ref&gt;，即系统的历史能够用来预测其未来行为的程度。通过构建预测模型，内在计算能够识别系统中的结构，并量化这些结构的复杂性和稳定性。它可以让我们能够将[[自组织]]视为系统中规律性和规则性的涌现，而这些规律性和规则性是系统在特定的初始条件和外部驱动下自发形成的。内在计算的一个重要应用是在理解从完全规则到完全无序之间的组织结构。比如，木星的大红斑是一个经典的自组织现象，其规模和稳定性无法通过简单的流体力学方程直接解释。然而，内在计算能够通过分析该现象的历史数据，构建出一个能够准确预测其未来行为的模型，从而揭示出其背后的自组织机制。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>预测等价性（predictive equivalence）是计算内在涌现（简称内在计算，intrinsic computation）的核心思想&lt;ref&gt;Rupe, A., &amp; Crutchfield, J. P. (2024). On principles of emergent organization. ''Physics Reports''.&lt;nowiki&gt;https://doi.org/10.1016/j.physlet.2024.06.017&lt;/nowiki&gt;&lt;/ref&gt;，即系统的历史能够用来预测其未来行为的程度。通过构建预测模型，内在计算能够识别系统中的结构，并量化这些结构的复杂性和稳定性。它可以让我们能够将[[自组织]]视为系统中规律性和规则性的涌现，而这些规律性和规则性是系统在特定的初始条件和外部驱动下自发形成的。内在计算的一个重要应用是在理解从完全规则到完全无序之间的组织结构。比如，木星的大红斑是一个经典的自组织现象，其规模和稳定性无法通过简单的流体力学方程直接解释。然而，内在计算能够通过分析该现象的历史数据，构建出一个能够准确预测其未来行为的模型，从而揭示出其背后的自组织机制。</div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">=== 因果态的主要性质 ===</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">在香农熵率确定的情况下，若要找到并计算模型的最小统计复杂度，我们首先需要最大限度地压缩环境信息，同时保证它的预测能力最强，因果态的性质恰好能满足这一需求，所以只要将环境信息转化为因果态，就能计算模型的统计复杂度。下面是因果态的三个主要性质：</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">'''性质1（因果态具有最大预测性）'''：对于所有划分得到的状态&lt;math&gt;\mathcal{R} &lt;/math&gt;和正整数&lt;math&gt;L &lt;/math&gt;，都有&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]\geq H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;，&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;为&lt;math&gt;L &lt;/math&gt;个长度的未来序列集合，&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}] &lt;/math&gt;和&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;是&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;的[[条件熵]]。可以理解为因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的预测能力最强，证明过程如下：</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;math&gt;\epsilon(\stackrel{\leftarrow}{s})\equiv\{\stackrel{\leftarrow}{s}^{\prime}|\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s})=\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s}^{\prime}) &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;math&gt;\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s} |\mathcal{S}=\epsilon(\stackrel{\leftarrow}{s}))=\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s}) &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{S}]~=~H[\stackrel{\rightarrow}{S}^L|~\stackrel{\leftarrow}{S}] &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;math&gt;H[\stackrel{\to}{S}^L|\mathcal{R}] \geq H[\stackrel{\to}{S}^L|\stackrel{\leftarrow}{S}] &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]\geq H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">'''性质2（因果态具有最小随机性）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;为满足性质1中不等式等号成立的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;，都有&lt;math&gt;H[\hat{\mathcal{R}}^{\prime}|\hat{\mathcal{R}}]\geq H[\mathcal{S}^{\prime}|\mathcal{S}] &lt;/math&gt;，其中&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;和&lt;math&gt;\mathcal{S}^{\prime} &lt;/math&gt;分别是该过程的下一时刻状态和下一时刻因果态。可以理解为在相同预测能力的前提下，因果态集合[math]\displaystyle{ \mathcal{S} }[/math]在划分得到的状态集合[math]\displaystyle{ \mathcal{R} }[/math]的所有类型中，它的随机性最小。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">用[[互信息]]的角度去理解的话，上式等价于&lt;math&gt;I(\mathcal{S}^{\prime};\mathcal{S})\geq I(\hat{\mathcal{R}}^{\prime};\hat{\mathcal{R}}) &lt;/math&gt;，可以理解为任意状态对它自己下一时刻的互信息中，其中因果态的互信息最大。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">若想更深入的理解因果态的性质可以阅读Cosma Rohilla Shalizi 和James Crutchfield合写的一篇论文&lt;ref name=&quot;:4&quot;&gt;Shalizi, C. R.. &amp; Crutchfield, J. P. (2001). Computational Mechanics: Pattern and Prediction, Structure and</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">Simplicity,Journal of Statistical Physics,104(3/4).817-879.&lt;/ref&gt;，里面有因果态更多的性质和对应的形式化证明过程。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===斑图重构机器===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===斑图重构机器===</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l118">第118行：</td>
<td class="diff-lineno" colspan="2">第141行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>如果在已确定描述语言（程序）的情况下，柯式复杂度[math]\displaystyle{ K(s^L ) }[/math]可以理解为描述[math]\displaystyle{ s^L }[/math]所用的总信息量。[math]\displaystyle{ h_μ L }[/math]为允许损失的信息量。统计复杂度[math]\displaystyle{ C_μ (s^L ) }[/math]可以理解为允许存在误差率[math]\displaystyle{ h_μ }[/math]的情况下，描述[math]\displaystyle{ s^L }[/math]所用的最少信息量。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>如果在已确定描述语言（程序）的情况下，柯式复杂度[math]\displaystyle{ K(s^L ) }[/math]可以理解为描述[math]\displaystyle{ s^L }[/math]所用的总信息量。[math]\displaystyle{ h_μ L }[/math]为允许损失的信息量。统计复杂度[math]\displaystyle{ C_μ (s^L ) }[/math]可以理解为允许存在误差率[math]\displaystyle{ h_μ }[/math]的情况下，描述[math]\displaystyle{ s^L }[/math]所用的最少信息量。</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">=== 因果态的主要性质 ===</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">在香农熵率确定的情况下，若要找到并计算模型的最小统计复杂度，我们首先需要最大限度地压缩环境信息，同时保证它的预测能力最强，因果态的性质恰好能满足这一需求，所以只要将环境信息转化为因果态，就能计算模型的统计复杂度。下面是因果态的三个主要性质：</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">'''性质1（因果态具有最大预测性）'''：对于所有划分得到的状态&lt;math&gt;\mathcal{R} &lt;/math&gt;和正整数&lt;math&gt;L &lt;/math&gt;，都有&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]\geq H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;，&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;为&lt;math&gt;L &lt;/math&gt;个长度的未来序列集合，&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}] &lt;/math&gt;和&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;是&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;的[[条件熵]]。可以理解为因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的预测能力最强，证明过程如下：</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;math&gt;\epsilon(\stackrel{\leftarrow}{s})\equiv\{\stackrel{\leftarrow}{s}^{\prime}|\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s})=\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s}^{\prime}) &lt;/math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;math&gt;\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s} |\mathcal{S}=\epsilon(\stackrel{\leftarrow}{s}))=\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s}) &lt;/math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{S}]~=~H[\stackrel{\rightarrow}{S}^L|~\stackrel{\leftarrow}{S}] &lt;/math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;math&gt;H[\stackrel{\to}{S}^L|\mathcal{R}] \geq H[\stackrel{\to}{S}^L|\stackrel{\leftarrow}{S}] &lt;/math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]\geq H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">'''性质2（因果态具有最小统计复杂度）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;为满足性质1中不等式等号成立时划分得到的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;，都有&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;。可以理解为在相同预测能力的前提下，因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的统计复杂度最小，证明过程如下：</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">对于任意的&lt;math&gt;\mathcal{R}&lt;/math&gt;，总存在确定的函数&lt;math&gt;g &lt;/math&gt;使得&lt;math&gt;\mathcal{S}=g(\mathcal{R}) &lt;/math&gt;成立。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">根据熵的性质，对于任意确定的函数&lt;math&gt;f &lt;/math&gt;，有&lt;math&gt;H[f(X)]\leqslant H[X] &lt;/math&gt;成立。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">所以&lt;math&gt;H[S]=H[g(\hat{\mathcal{R}})]\leqslant H[\hat{\mathcal{R}}] &lt;/math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">根据统计复杂度的计算方法可知，&lt;math&gt;C_\mu(\hat{\mathcal{R}})=H[\hat{\mathcal{R}}] &lt;/math&gt;。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">所以&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">'''性质3（因果态具有最小随机性）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;为满足性质1中不等式等号成立的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;，都有&lt;math&gt;H[\hat{\mathcal{R}}^{\prime}|\hat{\mathcal{R}}]\geq H[\mathcal{S}^{\prime}|\mathcal{S}] &lt;/math&gt;，其中&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;和&lt;math&gt;\mathcal{S}^{\prime} &lt;/math&gt;分别是该过程的下一时刻状态和下一时刻因果态。可以理解为在相同预测能力的前提下，因果态集合[math]\displaystyle{ \mathcal{S} }[/math]在划分得到的状态集合[math]\displaystyle{ \mathcal{R} }[/math]的所有类型中，它的随机性最小。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">用[[互信息]]的角度去理解的话，上式等价于&lt;math&gt;I(\mathcal{S}^{\prime};\mathcal{S})\geq I(\hat{\mathcal{R}}^{\prime};\hat{\mathcal{R}}) &lt;/math&gt;，可以理解为任意状态对它自己下一时刻的互信息中，其中因果态的互信息最大。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">若想更深入的理解因果态的性质可以阅读Cosma Rohilla Shalizi 和James Crutchfield合写的一篇论文&lt;ref name=&quot;:4&quot;&gt;Shalizi, C. R.. &amp; Crutchfield, J. P. (2001). Computational Mechanics: Pattern and Prediction, Structure and</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">Simplicity,Journal of Statistical Physics,104(3/4).817-879.&lt;/ref&gt;，里面有因果态更多的性质和对应的形式化证明过程。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===模型重构===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===模型重构===</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40171:rev-40185 -->
</table>

## 复杂网络中的因果涌现
[Read more](https://wiki.swarma.org/index.php?title=%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%9B%A0%E6%9E%9C%E6%B6%8C%E7%8E%B0&diff=40184&oldid=40129)

Updated: 2024-12-08T14:53:57Z

<p><span dir="auto"><span class="autocomment">贪婪算法</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月8日 (日) 14:53的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的1个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l103">第103行：</td>
<td class="diff-lineno" colspan="2">第103行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''输入'''：具有N个节点的网络[math]G[/math]，其邻接矩阵为：&lt;math&gt;A&lt;/math&gt;；'''输出'''：经过粗粒化后的宏观网络[math]G'[/math]，其邻接矩阵为：&lt;math&gt;B&lt;/math&gt;，以及从[math]A[/math]到[math]B[/math]的粗粒化方式</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''输入'''：具有N个节点的网络[math]G[/math]，其邻接矩阵为：&lt;math&gt;A&lt;/math&gt;；'''输出'''：经过粗粒化后的宏观网络[math]G'[/math]，其邻接矩阵为：&lt;math&gt;B&lt;/math&gt;，以及从[math]A[/math]到[math]B[/math]的粗粒化方式</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div># 初始化一个节点的集合[math]V[/math]，将[math]V[/math]中的每个节点所属的[[马尔可夫毯]]<del class="diffchange diffchange-inline">(这是一个节点的集合，既包括所有指向该节点和该节点指向的所有邻居节点，也包括被同一个父节点指向的兄弟节点）也加入集合中；</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div># 初始化一个节点的集合[math]V[/math]，将[math]V[/math]中的每个节点所属的[[马尔可夫毯]]<ins class="diffchange diffchange-inline">（这是一个节点的集合，既包括该节点的父节点、子节点以及子节点的其他父节点）也加入集合中；</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div># 遍历[math]G[/math]中的节点&lt;math&gt;\{v_i\}_{i=1}^N&lt;/math&gt;（如果节点已经被合并成宏观节点则跳过），直到所有的节点遍历一遍停止：</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div># 遍历[math]G[/math]中的节点&lt;math&gt;\{v_i\}_{i=1}^N&lt;/math&gt;（如果节点已经被合并成宏观节点则跳过），直到所有的节点遍历一遍停止：</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div># 初始化一个队列&lt;math&gt;Q&lt;/math&gt;, 取出集合V中&lt;math&gt;v_i&lt;/math&gt;对应的马尔可夫毯中的所有节点，将其加入队列中；</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div># 初始化一个队列&lt;math&gt;Q&lt;/math&gt;, 取出集合V中&lt;math&gt;v_i&lt;/math&gt;对应的马尔可夫毯中的所有节点，将其加入队列中；</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40129:rev-40184 -->
</table>

## 基于有效信息的因果涌现理论
[Read more](https://wiki.swarma.org/index.php?title=%E5%9F%BA%E4%BA%8E%E6%9C%89%E6%95%88%E4%BF%A1%E6%81%AF%E7%9A%84%E5%9B%A0%E6%9E%9C%E6%B6%8C%E7%8E%B0%E7%90%86%E8%AE%BA&diff=40182&oldid=40137)

Updated: 2024-12-08T10:56:37Z

<p><span dir="auto"><span class="autocomment">代码</span></span></p>
<a href="https://wiki.swarma.org/index.php?title=%E5%9F%BA%E4%BA%8E%E6%9C%89%E6%95%88%E4%BF%A1%E6%81%AF%E7%9A%84%E5%9B%A0%E6%9E%9C%E6%B6%8C%E7%8E%B0%E7%90%86%E8%AE%BA&amp;diff=40182&amp;oldid=40137">显示更改</a>

## 马尔科夫链的粗粒化
[Read more](https://wiki.swarma.org/index.php?title=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E7%9A%84%E7%B2%97%E7%B2%92%E5%8C%96&diff=40179&oldid=40160)

Updated: 2024-12-08T09:10:17Z

<p><span dir="auto"><span class="autocomment">最初定义</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月8日 (日) 09:10的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的7个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l101">第101行：</td>
<td class="diff-lineno" colspan="2">第101行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>给定一个任意state partition &lt;math&gt;A=\{A_1, A_2, ... ,A_r\}&lt;/math&gt;，也可以把其理解为宏观的状态空间。&lt;math&gt;S&lt;/math&gt; 和 &lt;math&gt;A&lt;/math&gt; 之间的Hard Partition映射关系&lt;math&gt;\Phi:S \rightarrow A&lt;/math&gt;为：&lt;math&gt;A_i \in S, A_i \neq \empty, A_i \cap A_j = \empty , \forall i, j, \cup_i A_i = S&lt;/math&gt;。这种映射关系是指：&lt;math&gt;A&lt;/math&gt;中的每个元素&lt;math&gt;A_i&lt;/math&gt;都包括了若干个&lt;math&gt;s_i&lt;/math&gt;；&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;之间没有交集，即每个&lt;math&gt;s_i&lt;/math&gt;不会同时属于&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;；&lt;math&gt;S&lt;/math&gt;中的每个元素必须属于某个&lt;math&gt;A&lt;/math&gt;的元素，即&lt;math&gt;A&lt;/math&gt;覆盖了&lt;math&gt;S&lt;/math&gt;。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>给定一个任意state partition &lt;math&gt;A=\{A_1, A_2, ... ,A_r\}&lt;/math&gt;，也可以把其理解为宏观的状态空间。&lt;math&gt;S&lt;/math&gt; 和 &lt;math&gt;A&lt;/math&gt; 之间的Hard Partition映射关系&lt;math&gt;\Phi:S \rightarrow A&lt;/math&gt;为：&lt;math&gt;A_i \in S, A_i \neq \empty, A_i \cap A_j = \empty , \forall i, j, \cup_i A_i = S&lt;/math&gt;。这种映射关系是指：&lt;math&gt;A&lt;/math&gt;中的每个元素&lt;math&gt;A_i&lt;/math&gt;都包括了若干个&lt;math&gt;s_i&lt;/math&gt;；&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;之间没有交集，即每个&lt;math&gt;s_i&lt;/math&gt;不会同时属于&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;；&lt;math&gt;S&lt;/math&gt;中的每个元素必须属于某个&lt;math&gt;A&lt;/math&gt;的元素，即&lt;math&gt;A&lt;/math&gt;覆盖了&lt;math&gt;S&lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>在这里，我们考虑的是线性的马尔科夫过程的投影，所以&lt;math&gt;\Phi&lt;/math&gt;是一个&lt;math&gt;n \times n&lt;/math&gt;的投影矩阵。因此，我们可以定义宏观状态&lt;math&gt;A^{(t)} = s^{(t)} \Phi&lt;/math&gt;为微观状态&lt;math&gt;s^{(t)}&lt;/math&gt;在宏观空间上的投影。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;u&gt;</ins>在这里，我们考虑的是线性的马尔科夫过程的投影，所以&lt;math&gt;\Phi&lt;/math&gt;是一个&lt;math&gt;n \times n&lt;/math&gt;的投影矩阵。因此，我们可以定义宏观状态&lt;math&gt;A^{(t)} = s^{(t)} \Phi&lt;/math&gt;为微观状态&lt;math&gt;s^{(t)}&lt;/math&gt;在宏观空间上的投影。<ins class="diffchange diffchange-inline">&lt;/u&gt;</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">[[文件:Lumpable矩阵粗粒化示例.png|缩略图|500x500像素|图2：矩阵粗粒化示例]]&lt;u&gt;</ins>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}<ins class="diffchange diffchange-inline">&lt;/math&gt;通过投影矩阵&lt;math&gt;\Phi</ins>&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。<ins class="diffchange diffchange-inline">&lt;/u&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;u&gt;比如，我们有某条微观状态序列&lt;math&gt;\{ s^{(1)}, ..., s^{(6)} \}&lt;/math&gt; 是 &lt;math&gt;\{ s_1, s_3, s_4, s_2, s_2, s_3  \}&lt;/math&gt;，对于投影矩阵&lt;math&gt;\Phi  = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )&lt;/math&gt;，我们得到的投影后的宏观状态序列为&lt;math&gt;\{ A_1, A_2, A_2, A_1, A_1, A_2  \}&lt;/math&gt;&lt;/u&gt;</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">[[文件:Lumpable矩阵粗粒化示例.png|缩略图|500x500像素|图2：矩阵粗粒化示例]]</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''''定义1'''''：'''Lumped process'''</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''''定义1'''''：'''Lumped process'''</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l147">第147行：</td>
<td class="diff-lineno" colspan="2">第148行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div># '''转移概率(Transition probability)，即式子(3.3)，对任何微观初始状态(starting vector) &lt;math&gt; \pi &lt;/math&gt; 都保持一致'''</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div># '''转移概率(Transition probability)，即式子(3.3)，对任何微观初始状态(starting vector) &lt;math&gt; \pi &lt;/math&gt; 都保持一致'''</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>不满足上述两个条件的，都不被定义为lumpable partition。也就是说，不是所有的lumped process都是lumpable的，即使他们的命名方式相似。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">[[文件:Lumpable和non-lumpable的例子.png|缩略图|图3：对lumpable和non-lumpable矩阵做粗粒化|替代=|600x600像素]]</ins>不满足上述两个条件的，都不被定义为lumpable partition。也就是说，不是所有的lumped process都是lumpable的，即使他们的命名方式相似。</div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;u&gt;从图3的lumpable例子中，我们看到对于分组矩阵&lt;math&gt;\Phi = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )&lt;/math&gt;，lumpable的动力学TPM可以找到一个lumped process，而这个lumped process是满足马尔可夫性，且对所有初始状态都保持一致的。也就是说，无论&lt;math&gt;s^{(t)}&lt;/math&gt;是什么，&lt;math&gt;\{ s^{(t)}, s^{(t+1)} \}&lt;/math&gt;投影到宏观空间上的&lt;math&gt;\{ A^{(t)}, A^{(t+1)} \}&lt;/math&gt;的&lt;math&gt; P( A^{(t+1)} | A^{(t)} )&lt;/math&gt;都保持一致。&lt;/u&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;u&gt;&lt;br /&gt;&lt;/u&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;u&gt;对于例子中的non-lumpable矩阵，我们或许可以给它强制定义一个lumped process的TPM，比如&lt;math&gt; P_1' = \left ( \begin{array}{cc} 0.6 &amp; 0.4 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;，但这个lumped process并不能对任何微观初始状态保持一致，只能对&lt;math&gt;s^{(t)} = \pi = \left [ \begin{array}{cc}1 &amp; 0 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;适用。&lt;/u&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;u&gt;而&lt;math&gt;s^{(t)} = \pi = \left [ \begin{array}{cc}0 &amp; 1 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;不适用这个lumped process。它适用的是&lt;math&gt; P_2' = \left ( \begin{array}{cc} 0.5 &amp; 0.5 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;。这里的不适用是指，这个lumped process不能描述这个&lt;math&gt;\pi&lt;/math&gt;为初始状态出发的微观状态序列投影的宏观状态序列。&lt;/u&gt;</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">[[文件:Lumpable和non-lumpable的例子.png|缩略图|图3：对lumpable和non-lumpable矩阵做粗粒化|替代=|600x600像素]]从图2的lumpable例子中，我们看到对于分组矩阵</del>&lt;math&gt;\Phi = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )&lt;/math&gt;<del class="diffchange diffchange-inline">，lumpable的动力学TPM是可以找到一个lumped process，而这个lumped process是满足马尔可夫性，且对所有初始状态都保持一致的。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;u&gt;我们看到，对于这个分组矩阵</ins>&lt;math&gt;\Phi = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )&lt;/math&gt;<ins class="diffchange diffchange-inline">，马尔科夫矩阵有两个lumped process &lt;math&gt; P_1'&lt;/math&gt;和&lt;math&gt; P_2'&lt;/math&gt;，而它们各自只适用于一些微观初始状态(starting vector) &lt;math&gt; \pi &lt;/math&gt;，并不满足定义2中的条件，所以&lt;math&gt;A&lt;/math&gt;对于这个TPM来说不是一个lumpable partition。事实上，这个TPM只存在一个lumpable partition，就是不做任何的分组，所以它无法按照lumpability的定义进行粗粒化。&lt;/u&gt;</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">在non-lumpable的矩阵，我们或许可以给它强制定义一个lumped process的TPM，比如&lt;math&gt; P_1' = \left ( \begin{array}{cc} 0.6 &amp; 0.4 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;，但这个lumped process并不能对任何微观初始状态保持一致，只能对&lt;math&gt;\pi = \left [ \begin{array}{cc}1 &amp; 0 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;适用。而&lt;math&gt;\pi = \left [ \begin{array}{cc}0 &amp; 1 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;不适用这个lumped process。它适用的是&lt;math&gt; P_2' = \left ( \begin{array}{cc} 0.5 &amp; 0.5 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;。这里的适用是指，&lt;math&gt; \pi &lt;/math&gt;按照这个lumped process到达对应的宏观态的概率，跟按照微观动力学后聚类到达宏观态的概率是相同的。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">我们看到，对于这个分组矩阵&lt;math&gt;\Phi = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )&lt;/math&gt;，马尔科夫矩阵有两个lumped process &lt;math&gt; P_1'&lt;/math&gt;和&lt;math&gt; P_2'&lt;/math&gt;，而它们各自只适用于一些微观初始状态(starting vector) &lt;math&gt; \pi &lt;/math&gt;，并不满足定义2中的条件，所以&lt;math&gt;A&lt;/math&gt;对于这个TPM来说不是一个lumpable partition。事实上，这个TPM只存在一个lumpable partition，就是不做任何的分组，所以它无法按照lumpability的定义进行粗粒化。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===lumpable partition的充分必要条件===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===lumpable partition的充分必要条件===</div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;u&gt;通过上面的例子，我们可以对lumpable partition有一些直观的理解。我们可以留意到，在lumpable partition中，有两个分组，所以有四个框。每一个框里，每一列相加的和都是一样的，比如左上角的框中，&lt;math&gt;0.3 + 0.3 = 0.2 + 0.4&lt;/math&gt;。这就是lumpable partition更通俗的解释，在某些文献中，并不会使用上面提及的定义，而是直接使用这个通俗版的解释。&lt;ref name=&quot;:3&quot; /&gt;中作者指出，这两者之间是存在充分必要条件关系的。&lt;/u&gt;</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>设&lt;math&gt;p_{s_k \rightarrow s_m} = p(s^{(t)} = s_m | s^{(t-1)} = s_k)&lt;/math&gt;，&lt;math&gt;p_{s_k \rightarrow A_i} = p(s^{(t)} \in A_i | s^{(t-1)} = s_k) = \sum_{s_m \in A_i} p_{s_k \rightarrow s_m}&lt;/math&gt;，&lt;math&gt;p_{A_i \rightarrow A_j} = p(A^{(t)} = A_j | A^{(t-1)} = A_i)&lt;/math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>设&lt;math&gt;p_{s_k \rightarrow s_m} = p(s^{(t)} = s_m | s^{(t-1)} = s_k)&lt;/math&gt;，&lt;math&gt;p_{s_k \rightarrow A_i} = p(s^{(t)} \in A_i | s^{(t-1)} = s_k) = \sum_{s_m \in A_i} p_{s_k \rightarrow s_m}&lt;/math&gt;，&lt;math&gt;p_{A_i \rightarrow A_j} = p(A^{(t)} = A_j | A^{(t-1)} = A_i)&lt;/math&gt;</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40160:rev-40179 -->
</table>

## 计算力学
[Read more](https://wiki.swarma.org/index.php?title=%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%AD%A6&diff=40171&oldid=40166)

Updated: 2024-12-08T07:22:41Z

<p><span dir="auto"><span class="autocomment">统计复杂度</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月8日 (日) 07:22的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的4个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l87">第87行：</td>
<td class="diff-lineno" colspan="2">第87行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;/math&gt;的最简单形式，且在该模型中尽量减少其复杂性。&lt;math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;/math&gt;的最简单形式，且在该模型中尽量减少其复杂性。&lt;math&gt;</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>\left\|⋅\right\|</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>\left\|⋅\right\|</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>&lt;/math&gt;<del class="diffchange diffchange-inline">这个符号表示对模型复杂度的量化，它可以是基于模型状态的数量、参数数量或计算资源的度量。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>&lt;/math&gt;<ins class="diffchange diffchange-inline">这个符号表示对模型复杂度的量化。由于内部模型作为一种图灵机，本身也是用字符串（因果态）来描述，所以可以用长度、香农熵等指标来度量内部模型的复杂度。当我们使用香农熵来刻画内部模型的复杂度时，我们可以给出对于观测序列来说，统计复杂度的一个可计算的定义：</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">根据因果态的定义可知，对于某个</del>&lt;math&gt;\mathcal{<del class="diffchange diffchange-inline">R</del>} &lt;/math&gt;<del class="diffchange diffchange-inline">的统计复杂度的计算式为</del>&lt;math&gt;<del class="diffchange diffchange-inline">C_\mu(</del>\mathcal{<del class="diffchange diffchange-inline">R</del>}<del class="diffchange diffchange-inline">)\equiv H[</del>\mathcal{<del class="diffchange diffchange-inline">R</del>}<del class="diffchange diffchange-inline">] </del>&lt;/math&gt;<del class="diffchange diffchange-inline">。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;<ins class="diffchange diffchange-inline">C_\mu(\mathcal{x})\equiv H[</ins>\mathcal{<ins class="diffchange diffchange-inline">S</ins>}<ins class="diffchange diffchange-inline">] </ins>&lt;/math&gt;<ins class="diffchange diffchange-inline">，其中</ins>&lt;math&gt;\mathcal{<ins class="diffchange diffchange-inline">S</ins>} <ins class="diffchange diffchange-inline">&lt;/math&gt;为观测数据&lt;math&gt;</ins>\mathcal{<ins class="diffchange diffchange-inline">x</ins>} &lt;/math&gt;<ins class="diffchange diffchange-inline">的因果态集合。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>相比之下，统计复杂度[math]\displaystyle{ C_μ(x) }[/math]剔除了通用图灵机在模拟随机比特时所花费的计算努力。统计复杂度的一个特征是，对于完全随机对象，有[math]\displaystyle{ C_μ(x)=0 }[/math]，如抛硬币产生的序列。同时对于简单的周期性过程，如[math]\displaystyle{ x=00000000…0 }[/math]时，也有[math]\displaystyle{ C_μ(x)=0 }[/math]。因此，统计复杂度的值对于（简单的）周期性过程和完全随机过程都很小。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>相比之下，统计复杂度[math]\displaystyle{ C_μ(x) }[/math]剔除了通用图灵机在模拟随机比特时所花费的计算努力。统计复杂度的一个特征是，对于完全随机对象，有[math]\displaystyle{ C_μ(x)=0 }[/math]，如抛硬币产生的序列。同时对于简单的周期性过程，如[math]\displaystyle{ x=00000000…0 }[/math]时，也有[math]\displaystyle{ C_μ(x)=0 }[/math]。因此，统计复杂度的值对于（简单的）周期性过程和完全随机过程都很小。</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l136">第136行：</td>
<td class="diff-lineno" colspan="2">第136行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''性质2（因果态具有最小统计复杂度）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;为满足性质1中不等式等号成立时划分得到的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;，都有&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;。可以理解为在相同预测能力的前提下，因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的统计复杂度最小，证明过程如下：</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''性质2（因果态具有最小统计复杂度）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;为满足性质1中不等式等号成立时划分得到的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;，都有&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;。可以理解为在相同预测能力的前提下，因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的统计复杂度最小，证明过程如下：</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>对于任意的&lt;math&gt;\mathcal{R}&lt;/math&gt;<del class="diffchange diffchange-inline">，若&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]= H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;，则存在函数</del>&lt;math&gt;g &lt;/math&gt;使得&lt;math&gt;\mathcal{S}=g(\mathcal{R}) &lt;/math&gt;<del class="diffchange diffchange-inline">总是成立。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>对于任意的&lt;math&gt;\mathcal{R}&lt;/math&gt;<ins class="diffchange diffchange-inline">，总存在确定的函数</ins>&lt;math&gt;g &lt;/math&gt;使得&lt;math&gt;\mathcal{S}=g(\mathcal{R}) &lt;/math&gt;<ins class="diffchange diffchange-inline">成立。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">根据</del>&lt;math&gt;<del class="diffchange diffchange-inline">\mathcal{R} &lt;/math&gt;的定义可知，&lt;math&gt;H[\vec{S}^L|\mathcal{R}]&lt;LH[S] </del>&lt;/math&gt;<del class="diffchange diffchange-inline">，则</del>&lt;math&gt;H[f(X)]\leqslant H[X] &lt;/math&gt;<del class="diffchange diffchange-inline">。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">根据熵的性质，对于任意确定的函数</ins>&lt;math&gt;<ins class="diffchange diffchange-inline">f </ins>&lt;/math&gt;<ins class="diffchange diffchange-inline">，有</ins>&lt;math&gt;H[f(X)]\leqslant H[X] &lt;/math&gt;<ins class="diffchange diffchange-inline">成立。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>所以&lt;math&gt;H[S]=H[g(\hat{\mathcal{R}})]\leqslant H[\hat{\mathcal{R}}] &lt;/math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>所以&lt;math&gt;H[S]=H[g(\hat{\mathcal{R}})]\leqslant H[\hat{\mathcal{R}}] &lt;/math&gt;</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l144">第144行：</td>
<td class="diff-lineno" colspan="2">第144行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>根据统计复杂度的计算方法可知，&lt;math&gt;C_\mu(\hat{\mathcal{R}})=H[\hat{\mathcal{R}}] &lt;/math&gt;。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>根据统计复杂度的计算方法可知，&lt;math&gt;C_\mu(\hat{\mathcal{R}})=H[\hat{\mathcal{R}}] &lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>所以&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>所以&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;<ins class="diffchange diffchange-inline">。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''性质3（因果态具有最小随机性）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;为满足性质1中不等式等号成立的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;，都有&lt;math&gt;H[\hat{\mathcal{R}}^{\prime}|\hat{\mathcal{R}}]\geq H[\mathcal{S}^{\prime}|\mathcal{S}] &lt;/math&gt;，其中&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;和&lt;math&gt;\mathcal{S}^{\prime} &lt;/math&gt;分别是该过程的下一时刻状态和下一时刻因果态。可以理解为在相同预测能力的前提下，因果态集合[math]\displaystyle{ \mathcal{S} }[/math]在划分得到的状态集合[math]\displaystyle{ \mathcal{R} }[/math]的所有类型中，它的随机性最小。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''性质3（因果态具有最小随机性）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;为满足性质1中不等式等号成立的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;，都有&lt;math&gt;H[\hat{\mathcal{R}}^{\prime}|\hat{\mathcal{R}}]\geq H[\mathcal{S}^{\prime}|\mathcal{S}] &lt;/math&gt;，其中&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;和&lt;math&gt;\mathcal{S}^{\prime} &lt;/math&gt;分别是该过程的下一时刻状态和下一时刻因果态。可以理解为在相同预测能力的前提下，因果态集合[math]\displaystyle{ \mathcal{S} }[/math]在划分得到的状态集合[math]\displaystyle{ \mathcal{R} }[/math]的所有类型中，它的随机性最小。</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40166:rev-40171 -->
</table>

## 计算力学
[Read more](https://wiki.swarma.org/index.php?title=%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%AD%A6&diff=40166&oldid=40151)

Updated: 2024-12-08T02:48:28Z

<p><span dir="auto"><span class="autocomment">因果态的主要性质</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月8日 (日) 02:48的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的4个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l88">第88行：</td>
<td class="diff-lineno" colspan="2">第88行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>\left\|⋅\right\|</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>\left\|⋅\right\|</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;/math&gt;这个符号表示对模型复杂度的量化，它可以是基于模型状态的数量、参数数量或计算资源的度量。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;/math&gt;这个符号表示对模型复杂度的量化，它可以是基于模型状态的数量、参数数量或计算资源的度量。</div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">根据因果态的定义可知，对于某个&lt;math&gt;\mathcal{R} &lt;/math&gt;的统计复杂度的计算式为&lt;math&gt;C_\mu(\mathcal{R})\equiv H[\mathcal{R}] &lt;/math&gt;。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>相比之下，统计复杂度[math]\displaystyle{ C_μ(x) }[/math]剔除了通用图灵机在模拟随机比特时所花费的计算努力。统计复杂度的一个特征是，对于完全随机对象，有[math]\displaystyle{ C_μ(x)=0 }[/math]，如抛硬币产生的序列。同时对于简单的周期性过程，如[math]\displaystyle{ x=00000000…0 }[/math]时，也有[math]\displaystyle{ C_μ(x)=0 }[/math]。因此，统计复杂度的值对于（简单的）周期性过程和完全随机过程都很小。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>相比之下，统计复杂度[math]\displaystyle{ C_μ(x) }[/math]剔除了通用图灵机在模拟随机比特时所花费的计算努力。统计复杂度的一个特征是，对于完全随机对象，有[math]\displaystyle{ C_μ(x)=0 }[/math]，如抛硬币产生的序列。同时对于简单的周期性过程，如[math]\displaystyle{ x=00000000…0 }[/math]时，也有[math]\displaystyle{ C_μ(x)=0 }[/math]。因此，统计复杂度的值对于（简单的）周期性过程和完全随机过程都很小。</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l98">第98行：</td>
<td class="diff-lineno" colspan="2">第100行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 香农熵率 ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 香农熵率 ===</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">上文中提到的随机性可以用香农熵率（Shannon </del>Entropy Rate）来度量，香农熵率是信息论中的一个概念，它是[[香农熵]]<del class="diffchange diffchange-inline">的扩展，主要用于描述时间序列在单位时间上的平均信息量。香农熵率是信息不确定性程度的归一化指标，信息的不确定性越高，香农熵率越大。如果环境信息生成的离散符号序列记作</del>[math]\displaystyle{ s^L }[/math] ，[math]\displaystyle{ L }[/math]为序列的长度，香农熵率记作[math]\displaystyle{ h_μ }[/math]，它与柯式复杂度[math]\displaystyle{ K(x) }[/math]的关系为：</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">上文中提到的一个序列的随机性可以用香农熵率（Shannon </ins>Entropy Rate）来度量，香农熵率是信息论中的一个概念，它是[[香农熵]]<ins class="diffchange diffchange-inline">的扩展，主要用于描述时间序列在单位时间上的平均信息量。香农熵率是信息不确定性程度的归一化指标，信息的不确定性越高，香农熵率越大。对于简单的周期性过程，如[math]\displaystyle{ x=00000000…0 }[/math]时，它的香农熵率为0，对于完全随机对象，如抛硬币产生的序列，它的香农熵率为1。如果环境信息生成的离散符号序列记作</ins>[math]\displaystyle{ s^L }[/math] ，[math]\displaystyle{ L }[/math]为序列的长度，香农熵率记作[math]\displaystyle{ h_μ }[/math]，它与柯式复杂度[math]\displaystyle{ K(x) }[/math]的关系为：</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l118">第118行：</td>
<td class="diff-lineno" colspan="2">第120行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 因果态的主要性质 ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 因果态的主要性质 ===</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">为了能够计算模型的统计复杂度[math]\displaystyle{ C_μ(x) }[/math]，我们首先需要最大限度地压缩环境信息，同时保证它的预测能力最强，因果态的性质恰好能满足这一需求，所以只要将环境信息转化为因果态，就能计算模型的统计复杂度。下面是因果态的三个主要性质：</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">在香农熵率确定的情况下，若要找到并计算模型的最小统计复杂度，我们首先需要最大限度地压缩环境信息，同时保证它的预测能力最强，因果态的性质恰好能满足这一需求，所以只要将环境信息转化为因果态，就能计算模型的统计复杂度。下面是因果态的三个主要性质：</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''性质1（因果态具有最大预测性）'''：对于所有划分得到的状态&lt;math&gt;\mathcal{R} &lt;/math&gt;和正整数&lt;math&gt;L &lt;/math&gt;，都有&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]\geq H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;，&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;为&lt;math&gt;L &lt;/math&gt;个长度的未来序列集合，&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}] &lt;/math&gt;和&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;是&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;的[[条件熵]]。可以理解为因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的预测能力最强，证明过程如下：</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''性质1（因果态具有最大预测性）'''：对于所有划分得到的状态&lt;math&gt;\mathcal{R} &lt;/math&gt;和正整数&lt;math&gt;L &lt;/math&gt;，都有&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]\geq H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;，&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;为&lt;math&gt;L &lt;/math&gt;个长度的未来序列集合，&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}] &lt;/math&gt;和&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;是&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;的[[条件熵]]。可以理解为因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的预测能力最强，证明过程如下：</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l140">第140行：</td>
<td class="diff-lineno" colspan="2">第142行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>所以&lt;math&gt;H[S]=H[g(\hat{\mathcal{R}})]\leqslant H[\hat{\mathcal{R}}] &lt;/math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>所以&lt;math&gt;H[S]=H[g(\hat{\mathcal{R}})]\leqslant H[\hat{\mathcal{R}}] &lt;/math&gt;</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">根据统计复杂度的定义可知，&lt;math&gt;C_\mu(\mathcal{R})\equiv H[\mathcal{R}] &lt;/math&gt;，则</del>&lt;math&gt;C_\mu(\hat{\mathcal{R}})=H[\hat{\mathcal{R}}] &lt;/math&gt;。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">根据统计复杂度的计算方法可知，</ins>&lt;math&gt;C_\mu(\hat{\mathcal{R}})=H[\hat{\mathcal{R}}] &lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>所以&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>所以&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40151:rev-40166 -->
</table>

## 马尔科夫链
[Read more](https://wiki.swarma.org/index.php?title=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE&diff=40161&oldid=0)

Updated: 2024-12-07T08:48:51Z

<p>建立内容为“马尔科夫链”的新页面</p>
<p><b>新页面</b></p><div>马尔科夫链</div>

## 马尔科夫链的粗粒化
[Read more](https://wiki.swarma.org/index.php?title=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E7%9A%84%E7%B2%97%E7%B2%92%E5%8C%96&diff=40160&oldid=40157)

Updated: 2024-12-06T15:32:54Z

<p><span dir="auto"><span class="autocomment">最初定义</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月6日 (五) 15:32的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的1个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l84">第84行：</td>
<td class="diff-lineno" colspan="2">第84行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>在这个词条里，我们主要讨论Hard partitioning，主要参考的是&lt;ref name=&quot;:0&quot;&gt;Zhang, Anru, and Mengdi Wang. &quot;Spectral state compression of markov processes.&quot; ''IEEE transactions on information theory'' 66.5 (2019): 3202-3231.&lt;/ref&gt;&lt;ref name=&quot;:3&quot; /&gt;，对Soft state aggregation感兴趣的朋友可以自行参阅S. P. Singh, T. Jaakkola, and M. I. Jordan, “Reinforcement learning with soft state aggregation&quot;&lt;ref&gt;Singh, Satinder, Tommi Jaakkola, and Michael Jordan. &quot;Reinforcement learning with soft state aggregation.&quot; ''Advances in neural information processing systems'' 7 (1994).&lt;/ref&gt;和Duan, Yaqi, Tracy Ke, and Mengdi Wang. &quot;State aggregation learning from markov transition data.&quot; ''Advances in Neural Information Processing Systems'' 32 (2019).&lt;ref&gt;Duan, Yaqi, Tracy Ke, and Mengdi Wang. &quot;State aggregation learning from markov transition data.&quot; ''Advances in Neural Information Processing Systems'' 32 (2019).&lt;/ref&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>在这个词条里，我们主要讨论Hard partitioning，主要参考的是&lt;ref name=&quot;:0&quot;&gt;Zhang, Anru, and Mengdi Wang. &quot;Spectral state compression of markov processes.&quot; ''IEEE transactions on information theory'' 66.5 (2019): 3202-3231.&lt;/ref&gt;&lt;ref name=&quot;:3&quot; /&gt;，对Soft state aggregation感兴趣的朋友可以自行参阅S. P. Singh, T. Jaakkola, and M. I. Jordan, “Reinforcement learning with soft state aggregation&quot;&lt;ref&gt;Singh, Satinder, Tommi Jaakkola, and Michael Jordan. &quot;Reinforcement learning with soft state aggregation.&quot; ''Advances in neural information processing systems'' 7 (1994).&lt;/ref&gt;和Duan, Yaqi, Tracy Ke, and Mengdi Wang. &quot;State aggregation learning from markov transition data.&quot; ''Advances in Neural Information Processing Systems'' 32 (2019).&lt;ref&gt;Duan, Yaqi, Tracy Ke, and Mengdi Wang. &quot;State aggregation learning from markov transition data.&quot; ''Advances in Neural Information Processing Systems'' 32 (2019).&lt;/ref&gt;</div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=Lumpability=</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=Lumpability=</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l94">第94行：</td>
<td class="diff-lineno" colspan="2">第97行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===最初定义===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===最初定义===</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>首先定义&lt;math&gt;s^{(t)}&lt;/math&gt;表示系统在&lt;math&gt;t&lt;/math&gt;<del class="diffchange diffchange-inline">时刻的微观状态，微观状态空间为</del>&lt;math&gt;S=\{s_1, s_2, ... ,s_n\}&lt;/math&gt;。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>首先定义&lt;math&gt;s^{(t)}&lt;/math&gt;表示系统在&lt;math&gt;t&lt;/math&gt;<ins class="diffchange diffchange-inline">时刻处于各微观状态的概率，微观状态空间为</ins>&lt;math&gt;S=\{s_1, s_2, ... ,s_n\}&lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>给定一个任意state partition &lt;math&gt;A=\{A_1, A_2, ... ,A_r\}&lt;/math&gt;，也可以把其理解为宏观的状态空间。&lt;math&gt;S&lt;/math&gt; 和 &lt;math&gt;A&lt;/math&gt; 之间的Hard Partition映射关系&lt;math&gt;\Phi:S \rightarrow A&lt;/math&gt;为：&lt;math&gt;A_i \in S, A_i \neq \empty, A_i \cap A_j = \empty , \forall i, j, \cup_i A_i = S&lt;/math&gt;。这种映射关系是指：&lt;math&gt;A&lt;/math&gt;中的每个元素&lt;math&gt;A_i&lt;/math&gt;都包括了若干个&lt;math&gt;s_i&lt;/math&gt;；&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;之间没有交集，即每个&lt;math&gt;s_i&lt;/math&gt;不会同时属于&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;；&lt;math&gt;S&lt;/math&gt;中的每个元素必须属于某个&lt;math&gt;A&lt;/math&gt;的元素，即&lt;math&gt;A&lt;/math&gt;覆盖了&lt;math&gt;S&lt;/math&gt;。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>给定一个任意state partition &lt;math&gt;A=\{A_1, A_2, ... ,A_r\}&lt;/math&gt;，也可以把其理解为宏观的状态空间。&lt;math&gt;S&lt;/math&gt; 和 &lt;math&gt;A&lt;/math&gt; 之间的Hard Partition映射关系&lt;math&gt;\Phi:S \rightarrow A&lt;/math&gt;为：&lt;math&gt;A_i \in S, A_i \neq \empty, A_i \cap A_j = \empty , \forall i, j, \cup_i A_i = S&lt;/math&gt;。这种映射关系是指：&lt;math&gt;A&lt;/math&gt;中的每个元素&lt;math&gt;A_i&lt;/math&gt;都包括了若干个&lt;math&gt;s_i&lt;/math&gt;；&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;之间没有交集，即每个&lt;math&gt;s_i&lt;/math&gt;不会同时属于&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;；&lt;math&gt;S&lt;/math&gt;中的每个元素必须属于某个&lt;math&gt;A&lt;/math&gt;的元素，即&lt;math&gt;A&lt;/math&gt;覆盖了&lt;math&gt;S&lt;/math&gt;。</div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">在这里，我们考虑的是线性的马尔科夫过程的投影，所以&lt;math&gt;\Phi&lt;/math&gt;是一个&lt;math&gt;n \times n&lt;/math&gt;的投影矩阵。因此，我们可以定义宏观状态&lt;math&gt;A^{(t)} = s^{(t)} \Phi&lt;/math&gt;为微观状态&lt;math&gt;s^{(t)}&lt;/math&gt;在宏观空间上的投影。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>[[文件:<del class="diffchange diffchange-inline">Lumpable和non-lumpable的例子</del>.png|缩略图|<del class="diffchange diffchange-inline">图2：对lumpable和non-lumpable矩阵做粗粒化</del>|<del class="diffchange diffchange-inline">替代=|600x600像素</del>]]</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>[[文件:<ins class="diffchange diffchange-inline">Lumpable矩阵粗粒化示例</ins>.png|缩略图|<ins class="diffchange diffchange-inline">500x500像素</ins>|<ins class="diffchange diffchange-inline">图2：矩阵粗粒化示例</ins>]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''''定义1'''''：'''Lumped process'''</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''''定义1'''''：'''Lumped process'''</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l143">第143行：</td>
<td class="diff-lineno" colspan="2">第149行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>不满足上述两个条件的，都不被定义为lumpable partition。也就是说，不是所有的lumped process都是lumpable的，即使他们的命名方式相似。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>不满足上述两个条件的，都不被定义为lumpable partition。也就是说，不是所有的lumped process都是lumpable的，即使他们的命名方式相似。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div> </div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">[[文件:Lumpable和non-lumpable的例子.png|缩略图|图3：对lumpable和non-lumpable矩阵做粗粒化|替代=|600x600像素]]</ins>从图2的lumpable例子中，我们看到对于分组矩阵&lt;math&gt;\Phi = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )&lt;/math&gt;，lumpable的动力学TPM是可以找到一个lumped process，而这个lumped process是满足马尔可夫性，且对所有初始状态都保持一致的。</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div> </div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>从图2的lumpable例子中，我们看到对于分组矩阵&lt;math&gt;\Phi = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )&lt;/math&gt;，lumpable的动力学TPM是可以找到一个lumped process，而这个lumped process是满足马尔可夫性，且对所有初始状态都保持一致的。</div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>在non-lumpable的矩阵，我们或许可以给它强制定义一个lumped process的TPM，比如&lt;math&gt; P_1' = \left ( \begin{array}{cc} 0.6 &amp; 0.4 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;，但这个lumped process并不能对任何微观初始状态保持一致，只能对&lt;math&gt;\pi = \left [ \begin{array}{cc}1 &amp; 0 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;适用。而&lt;math&gt;\pi = \left [ \begin{array}{cc}0 &amp; 1 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;不适用这个lumped process。它适用的是&lt;math&gt; P_2' = \left ( \begin{array}{cc} 0.5 &amp; 0.5 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;。这里的适用是指，&lt;math&gt; \pi &lt;/math&gt;按照这个lumped process到达对应的宏观态的概率，跟按照微观动力学后聚类到达宏观态的概率是相同的。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>在non-lumpable的矩阵，我们或许可以给它强制定义一个lumped process的TPM，比如&lt;math&gt; P_1' = \left ( \begin{array}{cc} 0.6 &amp; 0.4 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;，但这个lumped process并不能对任何微观初始状态保持一致，只能对&lt;math&gt;\pi = \left [ \begin{array}{cc}1 &amp; 0 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;适用。而&lt;math&gt;\pi = \left [ \begin{array}{cc}0 &amp; 1 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;不适用这个lumped process。它适用的是&lt;math&gt; P_2' = \left ( \begin{array}{cc} 0.5 &amp; 0.5 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;。这里的适用是指，&lt;math&gt; \pi &lt;/math&gt;按照这个lumped process到达对应的宏观态的概率，跟按照微观动力学后聚类到达宏观态的概率是相同的。</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l351">第351行：</td>
<td class="diff-lineno" colspan="2">第355行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>我们这里使用一个简单的lumpable partition例子，来显示lumpability的粗粒化跟HON是对应的。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>我们这里使用一个简单的lumpable partition例子，来显示lumpability的粗粒化跟HON是对应的。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lumpability例子示意图.png|缩略图|<del class="diffchange diffchange-inline">图3：例子示意图</del>|替代=]]</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lumpability例子示意图.png|缩略图|<ins class="diffchange diffchange-inline">图4：例子示意图</ins>|替代=]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l399">第399行：</td>
<td class="diff-lineno" colspan="2">第403行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>然后，我们来简单介绍一下的构建宏观HOM转移概率矩阵的计算方法。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>然后，我们来简单介绍一下的构建宏观HOM转移概率矩阵的计算方法。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">在图3中，我们看到3和4为待合并节点</del>&lt;math&gt;A&lt;/math&gt;。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">在图4中，我们看到3和4为待合并节点</ins>&lt;math&gt;A&lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>1. 对于其他节点到待合并节点&lt;math&gt;A&lt;/math&gt;<del class="diffchange diffchange-inline">的连边，即待合并节点的入流（图3中绿色的连边），我们直接加和即可，即</del>&lt;math&gt;p_{s_1 \rightarrow A} = 0.3+0.1=0.4&lt;/math&gt;，&lt;math&gt;p_{ s_2 \rightarrow A} = 0.2+0.3=0.5&lt;/math&gt;</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>1. 对于其他节点到待合并节点&lt;math&gt;A&lt;/math&gt;<ins class="diffchange diffchange-inline">的连边，即待合并节点的入流（图4中绿色的连边），我们直接加和即可，即</ins>&lt;math&gt;p_{s_1 \rightarrow A} = 0.3+0.1=0.4&lt;/math&gt;，&lt;math&gt;p_{ s_2 \rightarrow A} = 0.2+0.3=0.5&lt;/math&gt;</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>2. 对于待合并节点&lt;math&gt;A&lt;/math&gt;<del class="diffchange diffchange-inline">到其他节点的连边，即待合并节点的出流（图3中棕色的连边），我们需要考虑三种情况：</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>2. 对于待合并节点&lt;math&gt;A&lt;/math&gt;<ins class="diffchange diffchange-inline">到其他节点的连边，即待合并节点的出流（图4中棕色的连边），我们需要考虑三种情况：</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;间存在连边时；</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;间存在连边时；</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;指向同一个输出节点时；</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;指向同一个输出节点时；</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;指向不同输出节点时；</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;指向不同输出节点时；</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>待合并节点&lt;math&gt;A&lt;/math&gt;<del class="diffchange diffchange-inline">的出流的计算方式都不一样，如图4所示。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>待合并节点&lt;math&gt;A&lt;/math&gt;<ins class="diffchange diffchange-inline">的出流的计算方式都不一样，如图5所示。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:网络节点边权合并示意图.png|替代=|411x411像素]]</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:网络节点边权合并示意图.png|替代=|411x411像素]]</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l437">第437行：</td>
<td class="diff-lineno" colspan="2">第441行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>==基于Lumpability的粗粒化方法（未给定lumpable partition的情况）==</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>==基于Lumpability的粗粒化方法（未给定lumpable partition的情况）==</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lump fig1.png|缩略图|398x398像素|<del class="diffchange diffchange-inline">图5：Zhang</del>&lt;ref name=&quot;:0&quot; /&gt; 文章中的示意图。图中左面四个矩阵都是lumpable马尔科夫矩阵，而右面的P_2是一个噪声矩阵，(P_1)^T P_2 = 0|替代=]]</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lump fig1.png|缩略图|398x398像素|<ins class="diffchange diffchange-inline">图6：Zhang</ins>&lt;ref name=&quot;:0&quot; /&gt; 文章中的示意图。图中左面四个矩阵都是lumpable马尔科夫矩阵，而右面的P_2是一个噪声矩阵，(P_1)^T P_2 = 0|替代=]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>由上面的lumpability公式(4)<del class="diffchange diffchange-inline">和例子中我们能获得一个直观上的说法：当马尔科夫矩阵存在block结构，或者状态明显可被分成几类的时候，根据这样的partition，该矩阵就会lumpable，如图5中的</del>&lt;math&gt;\bar{P}&lt;/math&gt;所示，把相同的状态（行向量）分成一类的partition显然lumpable。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>由上面的lumpability公式(4)<ins class="diffchange diffchange-inline">和例子中我们能获得一个直观上的说法：当马尔科夫矩阵存在block结构，或者状态明显可被分成几类的时候，根据这样的partition，该矩阵就会lumpable，如图6中的</ins>&lt;math&gt;\bar{P}&lt;/math&gt;所示，把相同的状态（行向量）分成一类的partition显然lumpable。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">但是，有时候有些lumpable的矩阵的状态排序被打乱了（如图5中的</del>&lt;math&gt;P_1&lt;/math&gt;），或者矩阵包含了如&lt;math&gt;P_2&lt;/math&gt;<del class="diffchange diffchange-inline">的噪声（如图5中的</del>&lt;math&gt;P&lt;/math&gt;，&lt;math&gt;P = P_1 + P_2&lt;/math&gt;，&lt;math&gt;P_1^TP_2 = 0&lt;/math&gt;）。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">但是，有时候有些lumpable的矩阵的状态排序被打乱了（如图6中的</ins>&lt;math&gt;P_1&lt;/math&gt;），或者矩阵包含了如&lt;math&gt;P_2&lt;/math&gt;<ins class="diffchange diffchange-inline">的噪声（如图6中的</ins>&lt;math&gt;P&lt;/math&gt;，&lt;math&gt;P = P_1 + P_2&lt;/math&gt;，&lt;math&gt;P_1^TP_2 = 0&lt;/math&gt;）。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>我们在实际问题中很多时候要面对的是像&lt;math&gt;P&lt;/math&gt;这样的矩阵，我们既无法确定它是否lumpable，也无法决定它的partition，我们甚至不知道它的马尔科夫秩。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>我们在实际问题中很多时候要面对的是像&lt;math&gt;P&lt;/math&gt;这样的矩阵，我们既无法确定它是否lumpable，也无法决定它的partition，我们甚至不知道它的马尔科夫秩。</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l491">第491行：</td>
<td class="diff-lineno" colspan="2">第495行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>====动力学可逆性 v.s. Lumpability====</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>====动力学可逆性 v.s. Lumpability====</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">在lumpability的图5中我们提到了lumpable的马尔科夫矩阵可以被重新排列成几个block，这种lumpable的矩阵的动力学可逆性也会很高，在这种情况下动力学可逆性和 </del>Lumpability是一致的。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">在lumpability的图6中我们提到了lumpable的马尔科夫矩阵可以被重新排列成几个block，这种lumpable的矩阵的动力学可逆性也会很高，在这种情况下动力学可逆性和 </ins>Lumpability是一致的。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>在没有明显block结构的情况下，我们可以使用上述的SVD+kMeans方式找到最优的lumpability partition并决定它的lumpability。我们在一个动力学可逆性比较高（有明显的因果涌现）的国际贸易网的例子上尝试了一下，却发现该网络上的最优lumpability partition宏观结果的动力学可逆性并不高。这现象说明：</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>在没有明显block结构的情况下，我们可以使用上述的SVD+kMeans方式找到最优的lumpability partition并决定它的lumpability。我们在一个动力学可逆性比较高（有明显的因果涌现）的国际贸易网的例子上尝试了一下，却发现该网络上的最优lumpability partition宏观结果的动力学可逆性并不高。这现象说明：</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40157:rev-40160 -->
</table>

## 文件:Lumpable矩阵粗粒化示例.png
[Read more](https://wiki.swarma.org/index.php?title=%E6%96%87%E4%BB%B6:Lumpable%E7%9F%A9%E9%98%B5%E7%B2%97%E7%B2%92%E5%8C%96%E7%A4%BA%E4%BE%8B.png&diff=40158&oldid=0)

Updated: 2024-12-06T15:26:16Z

<p><a class="new mw-userlink" href="https://wiki.swarma.org/index.php?title=%E7%94%A8%E6%88%B7:Liangjh&amp;action=edit&amp;redlink=1" title="用户:Liangjh（页面不存在）">Liangjh</a>上传<a href="https://wiki.swarma.org/index.php/%E6%96%87%E4%BB%B6:Lumpable%E7%9F%A9%E9%98%B5%E7%B2%97%E7%B2%92%E5%8C%96%E7%A4%BA%E4%BE%8B.png" title="文件:Lumpable矩阵粗粒化示例.png">文件:Lumpable矩阵粗粒化示例.png</a></p>
<p><b>新页面</b></p><div>马尔科夫链的粗粒化</div>

## 马尔科夫链的粗粒化
[Read more](https://wiki.swarma.org/index.php?title=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E7%9A%84%E7%B2%97%E7%B2%92%E5%8C%96&diff=40157&oldid=40149)

Updated: 2024-12-06T15:01:59Z

<p></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月6日 (五) 15:01的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的3个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l25">第25行：</td>
<td class="diff-lineno" colspan="2">第25行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对马尔科夫链做粗粒化并没有一个统一的定义，目前该题目也没有一个完整的文献综述。在许多文献中，粗粒化coarse-graining，聚类/聚合partitioning/lumping/clustering/aggregation和降维dimension reduction是重叠等价的。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对马尔科夫链做粗粒化并没有一个统一的定义，目前该题目也没有一个完整的文献综述。在许多文献中，粗粒化coarse-graining，聚类/聚合partitioning/lumping/clustering/aggregation和降维dimension reduction是重叠等价的。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">多数文献中会出现如图一的定义</del>&lt;ref name=&quot;:2&quot;&gt;Coarse graining. ''Encyclopedia of Mathematics.'' URL: &lt;nowiki&gt;http://encyclopediaofmath.org/index.php?title=Coarse_graining&amp;oldid=16170&lt;/nowiki&gt;&lt;/ref&gt;：</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">多数文献中会出现如图1的定义</ins>&lt;ref name=&quot;:2&quot;&gt;Coarse graining. ''Encyclopedia of Mathematics.'' URL: &lt;nowiki&gt;http://encyclopediaofmath.org/index.php?title=Coarse_graining&amp;oldid=16170&lt;/nowiki&gt;&lt;/ref&gt;：</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:马尔科夫链粗粒化定义.png|替代=|缩略图|图1：粗粒化定义]]</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:马尔科夫链粗粒化定义.png|替代=|缩略图|图1：粗粒化定义]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对状态空间&lt;math&gt;S&lt;/math&gt;和转移函数&lt;math&gt;T(t):S \rightarrow S&lt;/math&gt;，我们需要一个投影矩阵&lt;math&gt;R:S \rightarrow S'&lt;/math&gt;，和一个新的转移函数&lt;math&gt;T'(t):S' \rightarrow S'&lt;/math&gt;，而且&lt;math&gt;S'&lt;/math&gt;和&lt;math&gt;T'&lt;/math&gt;要符合马尔科夫链定义。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对状态空间&lt;math&gt;S&lt;/math&gt;和转移函数&lt;math&gt;T(t):S \rightarrow S&lt;/math&gt;，我们需要一个投影矩阵&lt;math&gt;R:S \rightarrow S'&lt;/math&gt;，和一个新的转移函数&lt;math&gt;T'(t):S' \rightarrow S'&lt;/math&gt;，而且&lt;math&gt;S'&lt;/math&gt;和&lt;math&gt;T'&lt;/math&gt;要符合马尔科夫链定义。</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l83">第83行：</td>
<td class="diff-lineno" colspan="2">第83行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>在这个词条里，我们主要讨论Hard <del class="diffchange diffchange-inline">partitioning，主要参考的是Anru Zhang和Mengdi Wang的Spectral State Compression of Markov Processes</del>&lt;ref name=&quot;:0&quot;&gt;Zhang, Anru, and Mengdi Wang. &quot;Spectral state compression of markov processes.&quot; ''IEEE transactions on information theory'' 66.5 (2019): 3202-3231.&lt;/ref&gt;，对Soft state aggregation感兴趣的朋友可以自行参阅S. P. Singh, T. Jaakkola, and M. I. Jordan, “Reinforcement learning with soft state aggregation<del class="diffchange diffchange-inline">.</del>&quot;&lt;ref&gt;Singh, Satinder, Tommi Jaakkola, and Michael Jordan. &quot;Reinforcement learning with soft state aggregation.&quot; ''Advances in neural information processing systems'' 7 (1994).&lt;/ref&gt;</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>在这个词条里，我们主要讨论Hard <ins class="diffchange diffchange-inline">partitioning，主要参考的是</ins>&lt;ref name=&quot;:0&quot;&gt;Zhang, Anru, and Mengdi Wang. &quot;Spectral state compression of markov processes.&quot; ''IEEE transactions on information theory'' 66.5 (2019): 3202-3231.&lt;/ref<ins class="diffchange diffchange-inline">&gt;&lt;ref name=&quot;:3&quot; /</ins>&gt;，对Soft state aggregation感兴趣的朋友可以自行参阅S. P. Singh, T. Jaakkola, and M. I. Jordan, “Reinforcement learning with soft state aggregation&quot;&lt;ref&gt;Singh, Satinder, Tommi Jaakkola, and Michael Jordan. &quot;Reinforcement learning with soft state aggregation.&quot; ''Advances in neural information processing systems'' 7 (1994).&lt;/ref&gt;<ins class="diffchange diffchange-inline">和Duan, Yaqi, Tracy Ke, and Mengdi Wang. &quot;State aggregation learning from markov transition data.&quot; ''Advances in Neural Information Processing Systems'' 32 (2019).&lt;ref&gt;Duan, Yaqi, Tracy Ke, and Mengdi Wang. &quot;State aggregation learning from markov transition data.&quot; ''Advances in Neural Information Processing Systems'' 32 (2019).&lt;/ref&gt;</ins></div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div> </div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div> </div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=Lumpability=</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=Lumpability=</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l101">第101行：</td>
<td class="diff-lineno" colspan="2">第99行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lumpable和non-lumpable的例子.png|缩略图|<del class="diffchange diffchange-inline">对lumpable和non</del>-lumpable矩阵做粗粒化|替代=|600x600像素]]</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lumpable和non-lumpable的例子.png|缩略图|<ins class="diffchange diffchange-inline">图2：对lumpable和non</ins>-lumpable矩阵做粗粒化|替代=|600x600像素]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''''定义1'''''：'''Lumped process'''</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''''定义1'''''：'''Lumped process'''</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l145">第145行：</td>
<td class="diff-lineno" colspan="2">第143行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>不满足上述两个条件的，都不被定义为lumpable partition。也就是说，不是所有的lumped process都是lumpable的，即使他们的命名方式相似。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>不满足上述两个条件的，都不被定义为lumpable partition。也就是说，不是所有的lumped process都是lumpable的，即使他们的命名方式相似。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">从图2的lumpable和non-lumpable例子中，我们看到，lumpable矩阵是可以找到一个lumped process，而这个lumped process是满足马尔可夫性，且对所有初始状态都保持一致的。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">而non</del>-lumpable的矩阵，我们或许可以给它强制定义一个lumped process的TPM，比如&lt;math&gt; P_1' = \left ( \begin{array}{cc}</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>0.6 &amp; 0.4 \\</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">从图2的lumpable例子中，我们看到对于分组矩阵&lt;math&gt;\Phi = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )&lt;/math&gt;，lumpable的动力学TPM是可以找到一个lumped process，而这个lumped process是满足马尔可夫性，且对所有初始状态都保持一致的。</ins></div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>0.2 &amp; 0.8 \\</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>\end{array} \right )&lt;/math&gt;，但这个lumped process并不能对任何微观初始状态保持一致，只能对&lt;math&gt;<del class="diffchange diffchange-inline">s^{(t)} </del>= \left [ \begin{array}{cc}1 &amp; 0 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;<del class="diffchange diffchange-inline">适用。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">在non</ins>-lumpable的矩阵，我们或许可以给它强制定义一个lumped process的TPM，比如&lt;math&gt; P_1' = \left ( \begin{array}{cc} 0.6 &amp; 0.4 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;，但这个lumped process并不能对任何微观初始状态保持一致，只能对&lt;math&gt;<ins class="diffchange diffchange-inline">\pi </ins>= \left [ \begin{array}{cc}1 &amp; 0 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;<ins class="diffchange diffchange-inline">适用。而</ins>&lt;math&gt;<ins class="diffchange diffchange-inline">\pi </ins>= \left [ \begin{array}{cc}0 &amp; 1 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;不适用这个lumped process。它适用的是&lt;math&gt; P_2' = \left ( \begin{array}{cc} 0.5 &amp; 0.5 \\ 0.2 &amp; 0.8 \\ \end{array} \right )&lt;/math&gt;<ins class="diffchange diffchange-inline">。这里的适用是指，&lt;math&gt; \pi &lt;/math&gt;按照这个lumped process到达对应的宏观态的概率，跟按照微观动力学后聚类到达宏观态的概率是相同的。</ins></div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">而</del>&lt;math&gt;<del class="diffchange diffchange-inline">s^{(t)} </del>= \left [ \begin{array}{cc}0 &amp; 1 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;不适用这个lumped process。它适用的是&lt;math&gt; P_2' = \left ( \begin{array}{cc}</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>0.5 &amp; 0.5 \\</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">我们看到，对于这个分组矩阵</ins>&lt;math&gt;<ins class="diffchange diffchange-inline">\Phi = \left ( \begin{array}{cc} 1 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 1 \end{array} \right )</ins>&lt;/math&gt;，马尔科夫矩阵有两个lumped process &lt;math&gt; P_1'&lt;/math&gt;和&lt;math&gt; P_2'&lt;/math&gt;，而它们各自只适用于一些微观初始状态(starting vector) &lt;math&gt; \pi &lt;/math&gt;，并不满足定义2中的条件，所以&lt;math&gt;A&lt;/math&gt;<ins class="diffchange diffchange-inline">对于这个TPM来说不是一个lumpable partition。事实上，这个TPM只存在一个lumpable partition，就是不做任何的分组，所以它无法按照lumpability的定义进行粗粒化。</ins></div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>0.2 &amp; 0.8 \\</div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>\end{array} \right )&lt;/math&gt;<del class="diffchange diffchange-inline">。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">我们看到，对于这个state partition </del>&lt;math&gt;<del class="diffchange diffchange-inline">A</del>&lt;/math&gt;，马尔科夫矩阵有两个lumped process &lt;math&gt; P_1'&lt;/math&gt;和&lt;math&gt; P_2'&lt;/math&gt;，而它们各自只适用于一些微观初始状态(starting vector) &lt;math&gt; \pi &lt;/math&gt;，并不满足定义2中的条件，所以&lt;math&gt;A&lt;/math&gt;<del class="diffchange diffchange-inline">不是一个lumpable partition。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l284">第284行：</td>
<td class="diff-lineno" colspan="2">第278行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>这里我们就能看到，&lt;math&gt;p_{s_3 \rightarrow A_1} \neq p_{s_4 \rightarrow A_1}&lt;/math&gt;，当同一组的两个状态&lt;math&gt;s_3&lt;/math&gt;和&lt;math&gt;s_4&lt;/math&gt;对其他组的转移概率不一样的话，如果我们强行按照这样来分组（也没办法强行，因为我们不知道&lt;math&gt;p_{A_2 \rightarrow A_1} = p_{s_3 \rightarrow A_1}&lt;/math&gt;还是&lt;math&gt;p_{A_2 \rightarrow A_1} = p_{s_4 \rightarrow A_1}&lt;/math&gt;），假设&lt;math&gt;p_{A_2 \rightarrow A_1} = 0.6&lt;/math&gt;，我们会发现这样的粗粒化结果违背了Lumpability一开始的定义&lt;ref name=&quot;:3&quot; /&gt;（公式(3)），即粗粒化后的'''转移概率对所有的初始微观状态&lt;math&gt;\pi&lt;/math&gt;都适用'''。因为当&lt;math&gt;\pi = s_4&lt;/math&gt;的时候，&lt;math&gt;p_{A_2 \rightarrow A_1} = 0.6&lt;/math&gt;这个转移概率就是错的，即使&lt;math&gt;\pi \neq s_4&lt;/math&gt;，任何初始微观状态&lt;math&gt;\pi&lt;/math&gt;都会在某时刻&lt;math&gt;n&lt;/math&gt;达到&lt;math&gt;s_4&lt;/math&gt;并导致转移概率出错。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>这里我们就能看到，&lt;math&gt;p_{s_3 \rightarrow A_1} \neq p_{s_4 \rightarrow A_1}&lt;/math&gt;，当同一组的两个状态&lt;math&gt;s_3&lt;/math&gt;和&lt;math&gt;s_4&lt;/math&gt;对其他组的转移概率不一样的话，如果我们强行按照这样来分组（也没办法强行，因为我们不知道&lt;math&gt;p_{A_2 \rightarrow A_1} = p_{s_3 \rightarrow A_1}&lt;/math&gt;还是&lt;math&gt;p_{A_2 \rightarrow A_1} = p_{s_4 \rightarrow A_1}&lt;/math&gt;），假设&lt;math&gt;p_{A_2 \rightarrow A_1} = 0.6&lt;/math&gt;，我们会发现这样的粗粒化结果违背了Lumpability一开始的定义&lt;ref name=&quot;:3&quot; /&gt;（公式(3)），即粗粒化后的'''转移概率对所有的初始微观状态&lt;math&gt;\pi&lt;/math&gt;都适用'''。因为当&lt;math&gt;\pi = s_4&lt;/math&gt;的时候，&lt;math&gt;p_{A_2 \rightarrow A_1} = 0.6&lt;/math&gt;这个转移概率就是错的，即使&lt;math&gt;\pi \neq s_4&lt;/math&gt;，任何初始微观状态&lt;math&gt;\pi&lt;/math&gt;都会在某时刻&lt;math&gt;n&lt;/math&gt;达到&lt;math&gt;s_4&lt;/math&gt;并导致转移概率出错。</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l315">第315行：</td>
<td class="diff-lineno" colspan="2">第308行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>\end{aligned}</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>\end{aligned}</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;/math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;/math&gt;</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l359">第359行：</td>
<td class="diff-lineno" colspan="2">第351行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>我们这里使用一个简单的lumpable partition例子，来显示lumpability的粗粒化跟HON是对应的。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>我们这里使用一个简单的lumpable partition例子，来显示lumpability的粗粒化跟HON是对应的。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lumpability例子示意图.png|缩略图|<del class="diffchange diffchange-inline">图2：例子示意图</del>]]</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lumpability例子示意图.png|缩略图|<ins class="diffchange diffchange-inline">图3：例子示意图|替代=</ins>]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l407">第407行：</td>
<td class="diff-lineno" colspan="2">第399行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>然后，我们来简单介绍一下的构建宏观HOM转移概率矩阵的计算方法。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>然后，我们来简单介绍一下的构建宏观HOM转移概率矩阵的计算方法。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">在图2中，我们看到3和4为待合并节点</del>&lt;math&gt;A&lt;/math&gt;。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">在图3中，我们看到3和4为待合并节点</ins>&lt;math&gt;A&lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>1. 对于其他节点到待合并节点&lt;math&gt;A&lt;/math&gt;<del class="diffchange diffchange-inline">的连边，即待合并节点的入流（图2中绿色的连边），我们直接加和即可，即</del>&lt;math&gt;p_{s_1 \rightarrow A} = 0.3+0.1=0.4&lt;/math&gt;，&lt;math&gt;p_{ s_2 \rightarrow A} = 0.2+0.3=0.5&lt;/math&gt;</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>1. 对于其他节点到待合并节点&lt;math&gt;A&lt;/math&gt;<ins class="diffchange diffchange-inline">的连边，即待合并节点的入流（图3中绿色的连边），我们直接加和即可，即</ins>&lt;math&gt;p_{s_1 \rightarrow A} = 0.3+0.1=0.4&lt;/math&gt;，&lt;math&gt;p_{ s_2 \rightarrow A} = 0.2+0.3=0.5&lt;/math&gt;</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>2. 对于待合并节点&lt;math&gt;A&lt;/math&gt;<del class="diffchange diffchange-inline">到其他节点的连边，即待合并节点的出流（图2中棕色的连边），我们需要考虑三种情况：</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>2. 对于待合并节点&lt;math&gt;A&lt;/math&gt;<ins class="diffchange diffchange-inline">到其他节点的连边，即待合并节点的出流（图3中棕色的连边），我们需要考虑三种情况：</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;间存在连边时；</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;间存在连边时；</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;指向同一个输出节点时；</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;指向同一个输出节点时；</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;指向不同输出节点时；</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>#当待合并节点&lt;math&gt;A&lt;/math&gt;指向不同输出节点时；</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>待合并节点&lt;math&gt;A&lt;/math&gt;<del class="diffchange diffchange-inline">的出流的计算方式都不一样，如图3所示。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>待合并节点&lt;math&gt;A&lt;/math&gt;<ins class="diffchange diffchange-inline">的出流的计算方式都不一样，如图4所示。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:网络节点边权合并示意图.png|替代=|411x411像素]]</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:网络节点边权合并示意图.png|替代=|411x411像素]]</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l441">第441行：</td>
<td class="diff-lineno" colspan="2">第433行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>回到上面lumpable partition 等于HOM的推断，我们就能得出，'''根据lumpability而做的粗粒化，构建的宏观网络和微观网络也是保持一致的。'''</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>回到上面lumpable partition 等于HOM的推断，我们就能得出，'''根据lumpability而做的粗粒化，构建的宏观网络和微观网络也是保持一致的。'''</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>==基于Lumpability的粗粒化方法（未给定lumpable partition的情况）==</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>==基于Lumpability的粗粒化方法（未给定lumpable partition的情况）==</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lump fig1.png|缩略图|398x398像素|<del class="diffchange diffchange-inline">图4：Zhang</del>&lt;ref name=&quot;:0&quot; /&gt; 文章中的示意图。图中左面四个矩阵都是lumpable马尔科夫矩阵，而右面的P_2是一个噪声矩阵，(P_1)^T P_2 = 0|替代=]]</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lump fig1.png|缩略图|398x398像素|<ins class="diffchange diffchange-inline">图5：Zhang</ins>&lt;ref name=&quot;:0&quot; /&gt; 文章中的示意图。图中左面四个矩阵都是lumpable马尔科夫矩阵，而右面的P_2是一个噪声矩阵，(P_1)^T P_2 = 0|替代=]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>由上面的lumpability公式(4)<del class="diffchange diffchange-inline">和例子中我们能获得一个直观上的说法：当马尔科夫矩阵存在block结构，或者状态明显可被分成几类的时候，根据这样的partition，该矩阵就会lumpable，如图4中的</del>&lt;math&gt;\bar{P}&lt;/math&gt;所示，把相同的状态（行向量）分成一类的partition显然lumpable。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>由上面的lumpability公式(4)<ins class="diffchange diffchange-inline">和例子中我们能获得一个直观上的说法：当马尔科夫矩阵存在block结构，或者状态明显可被分成几类的时候，根据这样的partition，该矩阵就会lumpable，如图5中的</ins>&lt;math&gt;\bar{P}&lt;/math&gt;所示，把相同的状态（行向量）分成一类的partition显然lumpable。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">但是，有时候有些lumpable的矩阵的状态排序被打乱了（如图一中的</del>&lt;math&gt;P_1&lt;/math&gt;），或者矩阵包含了如&lt;math&gt;P_2&lt;/math&gt;<del class="diffchange diffchange-inline">的噪声（如图4中的</del>&lt;math&gt;P&lt;/math&gt;，&lt;math&gt;P = P_1 + P_2&lt;/math&gt;，&lt;math&gt;P_1^TP_2 = 0&lt;/math&gt;）。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">但是，有时候有些lumpable的矩阵的状态排序被打乱了（如图5中的</ins>&lt;math&gt;P_1&lt;/math&gt;），或者矩阵包含了如&lt;math&gt;P_2&lt;/math&gt;<ins class="diffchange diffchange-inline">的噪声（如图5中的</ins>&lt;math&gt;P&lt;/math&gt;，&lt;math&gt;P = P_1 + P_2&lt;/math&gt;，&lt;math&gt;P_1^TP_2 = 0&lt;/math&gt;）。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>我们在实际问题中很多时候要面对的是像&lt;math&gt;P&lt;/math&gt;这样的矩阵，我们既无法确定它是否lumpable，也无法决定它的partition，我们甚至不知道它的马尔科夫秩。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>我们在实际问题中很多时候要面对的是像&lt;math&gt;P&lt;/math&gt;这样的矩阵，我们既无法确定它是否lumpable，也无法决定它的partition，我们甚至不知道它的马尔科夫秩。</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l500">第500行：</td>
<td class="diff-lineno" colspan="2">第491行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>====动力学可逆性 v.s. Lumpability====</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>====动力学可逆性 v.s. Lumpability====</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">在lumpability的图1中我们提到了lumpable的马尔科夫矩阵可以被重新排列成几个block，这种lumpable的矩阵的动力学可逆性也会很高，在这种情况下动力学可逆性和 </del>Lumpability是一致的。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">在lumpability的图5中我们提到了lumpable的马尔科夫矩阵可以被重新排列成几个block，这种lumpable的矩阵的动力学可逆性也会很高，在这种情况下动力学可逆性和 </ins>Lumpability是一致的。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>在没有明显block结构的情况下，我们可以使用上述的SVD+kMeans方式找到最优的lumpability partition并决定它的lumpability。我们在一个动力学可逆性比较高（有明显的因果涌现）的国际贸易网的例子上尝试了一下，却发现该网络上的最优lumpability partition宏观结果的动力学可逆性并不高。这现象说明：</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>在没有明显block结构的情况下，我们可以使用上述的SVD+kMeans方式找到最优的lumpability partition并决定它的lumpability。我们在一个动力学可逆性比较高（有明显的因果涌现）的国际贸易网的例子上尝试了一下，却发现该网络上的最优lumpability partition宏观结果的动力学可逆性并不高。这现象说明：</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40149:rev-40157 -->
</table>

## 因果度量
[Read more](https://wiki.swarma.org/index.php?title=%E5%9B%A0%E6%9E%9C%E5%BA%A6%E9%87%8F&diff=40153&oldid=39924)

Updated: 2024-12-06T09:46:07Z

<p><span dir="auto"><span class="autocomment">一级因果性</span></span></p>
<a href="https://wiki.swarma.org/index.php?title=%E5%9B%A0%E6%9E%9C%E5%BA%A6%E9%87%8F&amp;diff=40153&amp;oldid=39924">显示更改</a>

## 计算力学
[Read more](https://wiki.swarma.org/index.php?title=%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%AD%A6&diff=40151&oldid=40145)

Updated: 2024-12-06T08:24:41Z

<p><span dir="auto"><span class="autocomment">香农熵率</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月6日 (五) 08:24的版本</td>
				</tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l98">第98行：</td>
<td class="diff-lineno" colspan="2">第98行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 香农熵率 ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 香农熵率 ===</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>上文中提到的随机性可以用香农熵率（Shannon Entropy Rate）来度量，香农熵率是信息论中的一个概念，它是[[香农熵]]<del class="diffchange diffchange-inline">的扩展，主要用于描述时间序列（如[[随机过程]]）的平均信息量。香农熵率是信息不确定性程度的归一化指标，信息的不确定性越高，香农熵率越大。如果环境信息生成的离散符号序列记作</del>[math]\displaystyle{ s^L }[/math] ，[math]\displaystyle{ L }[/math]为序列的长度，香农熵率记作[math]\displaystyle{ h_μ }[/math]，它与柯式复杂度[math]\displaystyle{ K(x) }[/math]的关系为：</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>上文中提到的随机性可以用香农熵率（Shannon Entropy Rate）来度量，香农熵率是信息论中的一个概念，它是[[香农熵]]<ins class="diffchange diffchange-inline">的扩展，主要用于描述时间序列在单位时间上的平均信息量。香农熵率是信息不确定性程度的归一化指标，信息的不确定性越高，香农熵率越大。如果环境信息生成的离散符号序列记作</ins>[math]\displaystyle{ s^L }[/math] ，[math]\displaystyle{ L }[/math]为序列的长度，香农熵率记作[math]\displaystyle{ h_μ }[/math]，它与柯式复杂度[math]\displaystyle{ K(x) }[/math]的关系为：</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;math&gt;</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40145:rev-40151 -->
</table>

## 因果度量中的因果基元
[Read more](https://wiki.swarma.org/index.php?title=%E5%9B%A0%E6%9E%9C%E5%BA%A6%E9%87%8F%E4%B8%AD%E7%9A%84%E5%9B%A0%E6%9E%9C%E5%9F%BA%E5%85%83&diff=40150&oldid=0)

Updated: 2024-12-06T08:11:42Z

<p>建立内容为“因果度量是通过科学方法和统计模型推断变量之间的因果关系，并衡量变量之间<a class="new" href="https://wiki.swarma.org/index.php?title=%E5%9B%A0%E6%9E%9C%E6%95%88%E5%BA%94%E5%BC%BA%E5%BA%A6&amp;action=edit&amp;redlink=1" title="因果效应强度（页面不存在）">因果效应强度</a>的方法。不同领域的科学…”的新页面</p>
<p><b>新页面</b></p><div>因果度量是通过科学方法和统计模型推断变量之间的因果关系，并衡量变量之间[[因果效应强度]]的方法。不同领域的科学家在选择因果度量方法时可能存在主观偏好，对是否存在因果关系的判定存在主观性。但这些因果度量方法在许多条件下在数学描述上表现却非常相似，具有相同的基本属性，这些相同的基本属性可以称作 “因果基元”。研究者们不再需要找到一个必须达成普遍共识的唯一因果关系衡量标准，而是可以通过关注这些相同的基本属性继续理解其他因果现象。<br />
<br />
==历史渊源==<br />
John Locke在他1690年发表的著作《人类理解论》中首次正式提出了因和果的概念：把产生观念的事物叫做原因，把所产生的东西叫做结果。在18世纪David Hume进一步发展了这个概念&lt;ref name=&quot;:1&quot;&gt;David Hume. ''An Enquiry concerning Human Understanding''. 1748.&lt;/ref&gt;，提出因果不是事实之间的概念，而是经验之间的习惯性联想。他强调判断因果关系的三条准则：空间邻近性、时间连续性、恒常连结性。20世纪70年代David Lewis推广了David Hume对因果关系的定义&lt;ref name=&quot;:2&quot;&gt;David Lewis. Causation. ''Journal of Philosophy'', 70(17):556–567, 1973.&lt;/ref&gt;，提出了判断因果关系的反事实推理法：“如果原因发生了，结果就会发生；如果原因不发生，结果就不会发生。”和这差不多的时间Ellery Eells和Patrick Suppes等人从概率论&lt;ref name=&quot;:3&quot;&gt;Ellery Eells. ''Probabilistic Causality''. Cambridge University Press, 1991.&lt;/ref&gt;&lt;ref name=&quot;:4&quot;&gt;Patrick Suppes. ''A Probabilistic Theory of Causality''. Amsterdam: North-Holland Pub. Co., 1968.&lt;/ref&gt;的角度给出了因果关系的定义，原因&lt;math&gt;c&lt;/math&gt;成为结果&lt;math&gt;e&lt;/math&gt;的原因的一个条件是，在&lt;math&gt;c&lt;/math&gt;存在的情况下&lt;math&gt;e&lt;/math&gt;的概率必须高于在&lt;math&gt;c&lt;/math&gt;不存在的情况下&lt;math&gt;e&lt;/math&gt;的概率。20世纪末Judea Pearl基于概率论和反事实的概念提出了结构因果模型和潜在结果模型，将因果关系划分为关联、干预、反事实三个层级，使得因果推理更加精确和实用&lt;ref name=&quot;:5&quot;&gt;Judea Pearl. ''Causality.'' Cambridge University Press, Cambridge, 2 edition, 2009.&lt;/ref&gt;。进入21世纪初Giulio Tononi 和 Olaf Sporns 提出[[有效信息|有效信息 (EI)]]的概念&lt;ref name=&quot;:6&quot;&gt;Giulio Tononi and Olaf Sporns. Measuring information integration. ''BMC Neuroscience'', page 20, 2003.&lt;/ref&gt;，它可以用来衡量一个马尔科夫动力学的因果效应强度。最近的2022年Erik hoel发表的一篇论文&lt;ref&gt;Comolatti, R., &amp; Hoel, E. (2022). Causal emergence is widespread across measures of causation. ''arXiv:2202.01854 [physics.soc-ph]''. &lt;nowiki&gt;https://doi.org/10.48550/arXiv.2202.01854&lt;/nowiki&gt;&lt;/ref&gt;中总结了各类因果度量方法中存在的相同基本属性。<br />
==因果关系的形式化==<br />
为了归纳各个因果度量方法之间的相似性，需要用一套统一的形式化方法描述它们，所以我们需要先给出因果关系的形式化方法：在一个给定的空间&lt;math&gt;Ω&lt;/math&gt;，即所有可能发生的情况的集合，在这个空间中，事件的单个原因记作&lt;math&gt;c&lt;/math&gt;，单个结果记作&lt;math&gt;e&lt;/math&gt;，，一组原因记作&lt;math&gt;C&lt;/math&gt; ，一组结果记作&lt;math&gt;E&lt;/math&gt;，其中假定&lt;math&gt;c&lt;/math&gt;在&lt;math&gt;e&lt;/math&gt;之前，并满足&lt;math&gt;c∈Ω 、 e∈Ω 、C ⊆ Ω 、 E ⊆ Ω&lt;/math&gt; 。为了衡量因果关系，把没有发生&lt;math&gt;c&lt;/math&gt;的情况下获得&lt;math&gt;e&lt;/math&gt;的概率写成&lt;math&gt;P (e|C\c)&lt;/math&gt;，其中&lt;math&gt;P&lt;/math&gt;代表概率，&lt;math&gt;C\c&lt;/math&gt;代表&lt;math&gt;c&lt;/math&gt;的补集，指的是在&lt;math&gt;C&lt;/math&gt;中的任何原因都可能产生&lt;math&gt;e&lt;/math&gt;的情况下，除了&lt;math&gt;c&lt;/math&gt;之外，&lt;math&gt;e&lt;/math&gt;的概率，用公式表示为<br />
<br />
&lt;math&gt;P(e\mid C)=\sum_{c\in C}P(c)P(e\mid c)&lt;/math&gt;<br />
==主要因果度量方法==<br />
===David Hume的恒常连结===<br />
David Hume将因果定义为“一个对象，后面跟着另一个对象，并且所有与第一个对象相似的对象后面跟着与第二个对象相似的对象”&lt;ref name=&quot;:1&quot; /&gt;。换句话说，因果关系源于事件之间的这种连续规律性模式&lt;ref&gt;Phyllis Illari and Federica Russo. ''Causality: Philosophical Theory meets Scientific Practice''. Oxford University Press, Oxford, New York, December 2014.&lt;/ref&gt;。 总体而言，事件&lt;math&gt;c&lt;/math&gt;后面跟着事件 &lt;math&gt;e&lt;/math&gt;的“恒常连结”会让我们预期一旦观察到&lt;math&gt;c&lt;/math&gt;，就会发生&lt;math&gt;e&lt;/math&gt;，因此推断&lt;math&gt;c&lt;/math&gt;是&lt;math&gt;e&lt;/math&gt;的原因。在这里，我们遵循 Judea Pearl 的观点，他将David Hume的连续规律性概念解释为我们今天所说的事件之间的相关性&lt;ref name=&quot;:5&quot; /&gt;。这可以形式化为候选原因&lt;math&gt;c&lt;/math&gt;和结果&lt;math&gt;e&lt;/math&gt;之间观察到的统计协方差：<br />
<br />
&lt;math&gt;\operatorname{Cov}(X, Y)=E(X Y)-E(X) E(Y)&lt;/math&gt;<br />
<br />
[math]\displaystyle{ E(X) }[/math]和[math]\displaystyle{ E(Y) }[/math]分别是随机变量[math]\displaystyle{ X }[/math]和[math]\displaystyle{ Y }[/math]的期望值，即各自独立时的平均结果。[math]\displaystyle{ E(XY) }[/math]这是随机变量[math]\displaystyle{ X }[/math]和[math]\displaystyle{ Y }[/math]乘积的期望值，表示在多次实验中，[math]\displaystyle{ X }[/math]和[math]\displaystyle{ Y }[/math]乘积的平均结果。如果我们用指示函数<br />
<br />
[math]\displaystyle{ X_{c} }[/math]（以及​[math]\displaystyle{ Y_{e} }[/math]）来替换上述方程中的变量，其中[math]\displaystyle{ X_{c} }[/math]（以及​[math]\displaystyle{ Y_{e} }[/math]）在[math]\displaystyle{ c }[/math]（或[math]\displaystyle{ e }[/math]）发生时取值为1，否则取值为0，那么就可以得到一个新的方程：<br />
<br />
[math]\displaystyle{ \begin{aligned} Cov(X_{c},Y_{e})&amp; =P(c,e)-P(c)P(e) \\ &amp;=P(c)P(e\mid c)-P(c)[P(c)P(e\mid c)+P(\bar{c})P(e\mid C\backslash c)] \\ &amp;=P(e\mid c)P(c)[1-P(c)]+P(c)P(C\backslash c)P(e\mid C\backslash c) \\ &amp;=P(e\mid c)P(c)P(C\backslash c)]+P(c)P(C\backslash c)P(e\mid C\backslash c) \\ &amp;=P(c)P(C\backslash c)[P(e\mid c)-P(e\mid C\backslash c)]) \end{aligned} }[/math]<br />
<br />
我们利用了这样一个事实：&lt;math&gt;P(e\mid c)&lt;/math&gt;可以分解为两个加权和，即&lt;math&gt;c&lt;/math&gt;和&lt;math&gt;C\c&lt;/math&gt;。按照其他人的命名法&lt;ref&gt;Branden Fitelson and Christopher Hitchcock. Probabilistic Measures of Causal Strength. ''Causality in the Sciences'', January 2010.&lt;/ref&gt;，我们将其称为因果强度的“高尔顿测度（Galton measure）”，因为它与生物学中性状遗传的形式非常相似，也是统计协方差的一种形式，最后得到David Hume的恒常连结形式化公式：<br />
<br />
&lt;math&gt;CS_{Galton}(e,c)=P(c)P(C\backslash c)[P(e\mid c)-P(e\mid C\backslash c)]&lt;/math&gt;<br />
===Eells 的因果关系度量是概率提升===<br />
Ellery Eells提出&lt;ref name=&quot;:3&quot; /&gt;，&lt;math&gt;c&lt;/math&gt;成为&lt;math&gt;e&lt;/math&gt;的原因的一个条件是，&lt;math&gt;c&lt;/math&gt;存在时&lt;math&gt;e&lt;/math&gt;发生的概率必须高于其不存在时&lt;math&gt;e&lt;/math&gt;发生的概率，这可以用因果强度的度量形式化为两个量之间的差：<br />
<br />
&lt;math&gt;CS_{Eells}=P(e\mid c)-P(e\mid C\backslash c)&lt;/math&gt;<br />
===Suppes将因果关系度量为概率提升===<br />
哲学家和科学家Patrick Suppes将因果关系定义为概率增加&lt;ref name=&quot;:4&quot; /&gt;。用我们的形式化方法可以表示为：<br />
<br />
&lt;math&gt;CS_{Suppes}(c,e)=P(e\mid c)-P(e\mid C)&lt;/math&gt;<br />
<br />
&lt;math&gt;CS_{Eells}&lt;/math&gt;和&lt;math&gt;CS_{Suppes}&lt;/math&gt;测量方法之间的区别在于，从测量&lt;math&gt;c&lt;/math&gt;对&lt;math&gt;e&lt;/math&gt;的因果必要性（即&lt;math&gt;c&lt;/math&gt;是否可以由&lt;math&gt;c&lt;/math&gt;以外的其他原因产生）转变为评估产生&lt;math&gt;e&lt;/math&gt;的方法的多样性（它衡量的是通过多少种不同的方式可以实现&lt;math&gt;e&lt;/math&gt;）。两者都是有效的措施，事实上在某些情况下是等效的&lt;ref&gt;Christopher Hitchcock. Probabilistic Causation. In Edward N. Zalta, editor, T''he Stanford Encyclopedia of Philosophy''.Metaphysics Research Lab, Stanford University, spring 2021 edition, 2018.&lt;/ref&gt;。<br />
<br />
请注意，我们可以把条件概率 &lt;math&gt;P(e\mid C\backslash c)&lt;/math&gt;扩展为&lt;math&gt;P(e\mid C)&lt;/math&gt;，包括&lt;math&gt;c&lt;/math&gt;本身。如果是这样，我们考虑的就不仅仅是在没有&lt;math&gt;c&lt;/math&gt;的情况下能否产生&lt;math&gt;e&lt;/math&gt;，而是&lt;math&gt;e&lt;/math&gt;可能出现的所有方式，包括通过&lt;math&gt;c&lt;/math&gt;本身。因此，另一个版本可以定义为：<br />
<br />
&lt;math&gt;C S_{\text {Suppes }_{I I}}(c, e)=\frac{P(e \mid c)}{P(e \mid C)}&lt;/math&gt;<br />
===程氏的因果归因===<br />
Patricia Cheng 提出了一个广受欢迎的因果归因心理学模型，在这个模型中，推理者不仅要评估事件之间的纯粹共变关系（即两个事件是否同时发生或变化），还要估计候选原因产生（或阻止）结果的 “因果能力”&lt;ref&gt;Patricia W. Cheng and Laura R. Novick. Causes versus enabling conditions. ''Cognition'', 40(1):83–120, August 1991.&lt;/ref&gt;，它衡量的是&lt;math&gt;c&lt;/math&gt;对&lt;math&gt;e&lt;/math&gt;的影响程度。在这一模型中，&lt;math&gt;c&lt;/math&gt;产生&lt;math&gt;e&lt;/math&gt;的因果能力由以下公式给出：<br />
<br />
&lt;math&gt;CS_{Cheng}(c,e)=\frac{P(e\mid c)-P(e\mid C\backslash c)}{1-P(e\mid C\backslash c)}&lt;/math&gt;<br />
===Lewis的反事实因果理论===<br />
David Lewis基于反事实（counterfactuals）对因果关系进行了另一种实质性的、有影响力的解释&lt;ref name=&quot;:2&quot; /&gt;。Lewis给因果关系下的定义是：如果给定事件的&lt;math&gt;c&lt;/math&gt;和&lt;math&gt;e&lt;/math&gt;都发生了，当且仅当“&lt;math&gt;c&lt;/math&gt;没有发生，那么&lt;math&gt;e&lt;/math&gt;就不会发生”这一情况成立时，&lt;math&gt;c&lt;/math&gt;才是&lt;math&gt;e&lt;/math&gt;的原因。刘易斯还把他的理论扩展到了 “不确定的世界”，在这种世界里&lt;ref&gt;David Lewis. Postscripts to ’Causation’. ''Philosophical Papers Vol. Ii'', 1986.&lt;/ref&gt;，&lt;math&gt;e&lt;/math&gt;可能只是以一定的概率跟随&lt;math&gt;c&lt;/math&gt;发生。在这种情况下，&lt;math&gt;c&lt;/math&gt;仍然可以被视为&lt;math&gt;e&lt;/math&gt;的原因，但这种因果关系是概率性的，而不是确定性的。按照Fitelson和Hitchcock提出的一种使用概率来度量因果强度的方法&lt;ref name=&quot;:0&quot;&gt;Branden Fitelson and Christopher Hitchcock. Probabilistic Measures of Causal Strength. ''Causality in the Sciences'',January 2010.&lt;/ref&gt;，，我们将Lewis的因果强度正式表述为比率：&lt;math&gt;\frac{P(e\mid c)}{P(e\mid C\setminus c)}&lt;/math&gt;。这个定义也被称为 “相对风险”：“它是指有 c 时发生 e 的风险与没有 c 时发生 e 的风险的比较”&lt;ref name=&quot;:0&quot; /&gt;。利用&lt;math&gt;p/q\to(p-q)/p&lt;/math&gt;映射，可以对这一指标进行归一化处理，得到一个在-1到1范围内的度量：<br />
<br />
&lt;math&gt;CS_{Lewis}(c,e)=\frac{P(e\mid c)-P(e\mid C\backslash c)}{P(e\mid c)}&lt;/math&gt;<br />
===Judea Pearl的因果关系测量方法===<br />
Judea Pearl，他在因果关系的研究中重新定义了以前的&lt;math&gt;CS_{Eells}&lt;/math&gt;、&lt;math&gt;CS_{Lewis}&lt;/math&gt;和&lt;math&gt;CS_{Cheng}&lt;/math&gt;三种测量方法&lt;ref&gt;Judea Pearl. ''Causality.'' Cambridge University Press, Cambridge, 2 edition, 2009.&lt;/ref&gt;。并把它们重新命名为关联（PNS）、干预（PN）和反事实（PS）,形式化的表示为：<br />
<br />
&lt;math&gt;\mathrm{PNS}=P(e\mid c)-P(e\mid C\backslash c)&lt;/math&gt;，<br />
<br />
&lt;math&gt;\mathrm{PN}=\frac{P(e\mid c)-P(e\mid C\backslash c)}{P(e\mid c)}&lt;/math&gt;，<br />
<br />
&lt;math&gt;\mathrm{PS}=\frac{P(e\mid c)-P(e\mid C\backslash c)}{1-P(e\mid C\backslash c)}&lt;/math&gt;<br />
===最接近的可能世界因果关系===<br />
David Lewis传统上给出了一种因果关系的反事实理论，其中反事实被指定为&lt;math&gt;c&lt;/math&gt;没有发生的最接近的可能世界&lt;ref&gt;David Lewis. Causation. ''Journal of Philosophy'', 70(17):556–567, 1973.&lt;/ref&gt;。换句话说，如果我们想知道某个事件c是否导致了另一个事件e，我们可以考虑一个假想的世界，在这个世界中c没有发生，然后观察e是否仍然会发生。为了使这一想法形式化，我们需要在单纯的概率转换之外添加进一步的结构。也就是说，这种测量需要一种可能状态（或 “世界”）之间的距离概念。一种简单的方法是使用二进制状态标签，利用汉明距离（Hamming distance）&lt;ref&gt;Luciano Floridi. Information, possible worlds and the cooptation of scepticism. ''Synthese'', 175:63–88, 2010.Publisher: Springer.&lt;/ref&gt;（将一个二进制字符串转换成另一个二进制字符串所需的比特翻转次数）来诱导度量。通过使用汉明距离作为度量，我们可以在一个状态空间中诱导出一个度量空间。这样，我们就可以定义Lewis所说的“最近的可能世界”，即与当前世界在汉明距离上最接近的世界，形式化公式为：&lt;math&gt;\bar{c}_{CPW}=\min_{c'}D_H(c,c')&lt;/math&gt; ，&lt;math&gt;D_H(c,c')&lt;/math&gt;为&lt;math&gt;c&lt;/math&gt;和&lt;math&gt;c'&lt;/math&gt;之间的汉明距离。有了这一点，我们就可以根据Lewis关于因果关系的论述来定义另一种测量方法，即从最接近的可能世界的反事实出发进行推理：<br />
<br />
&lt;math&gt;CS_{Lewis CPW}=\frac{P(e\mid c)-P(e\mid\bar{c}_{CPW})}{P(e\mid c)}&lt;/math&gt;<br />
===位翻转措施===<br />
另一种依赖于状态间距离概念的测量方法是测量系统中最小变化所产生的差异量。例如，某个局部扰动造成的比特翻转结果。文献&lt;ref&gt;Bryan C. Daniels, Hyunju Kim, Douglas Moore, Siyu Zhou, Harrison B. Smith, Bradley Karas, Stuart A. Kauffman,and Sara I. Walker. Criticality Distinguishes the Ensemble of Biological Regulatory Networks. ''Physical Review Letters'', 121(13):138102, September 2018. Publisher: American Physical Society.&lt;/ref&gt;中给出了这样一种测量方法：“当一个随机比特在时间 t 被翻转时，扰动状态与未扰动状态在时间 t + 1 之间的平均汉明距离”。虽然最初是在确定性假设下提出的，但我们在此将其扩展到非确定性系统，即：<br />
<br />
&lt;math&gt;CS_{bit-flip}(e,c)=\frac{1}{N}\sum_{i}^{N}\sum_{e^{\prime}\in E}P(e^{\prime}\mid c_{[i]})D_{H}(e,e^{\prime})&lt;/math&gt;<br />
<br />
其中&lt;math&gt;c_{[i]}&lt;/math&gt;对应于第&lt;math&gt;i^{th}&lt;/math&gt;位被翻转的状态，（例如，如果 c = 000，则 c[3] = 001），&lt;math&gt;D_H(e,e')&lt;/math&gt;为&lt;math&gt;e&lt;/math&gt;和&lt;math&gt;e'&lt;/math&gt;之间的汉明距离。<br />
===实际因果关系和效果信息===<br />
最近，有人提出了一个利用[[信息论]]评估动态因果网络实际因果关系的框架&lt;ref&gt;Larissa Albantakis, William Marshall, Erik Hoel, and Giulio Tononi. What Caused What? A Quantitative Account of Actual Causation Using Dynamical Causal Networks. ''Entropy'', 21(5):459, May 2019.&lt;/ref&gt;。根据这一框架，一个候选原因必须使得其结果发生的概率高于在未指定该原因时的结果发生概率。量化指标是效应信息（effect information），用来描述一个事件（原因）对其结果（效果）的信息贡献程度。简单来说，就是衡量一个原因在多大程度上能够增加其结果发生的可能性。如果一个原因能够显著提高某个结果发生的概率，那么我们就可以认为这个原因是有效的。其值为：<br />
<br />
&lt;math&gt;ei(c,e)=\log_2\frac{P(e\mid c)}{P(e\mid C)}=\log_2n[det(e,c)-deg(c)]&lt;/math&gt;<br />
<br />
请注意，效果信息实际上只是&lt;math&gt;C S_{\text {Suppes }_{I I}}&lt;/math&gt;的对数，这表明研究者新发现的因果度量方法与已经发现的因果度量方法在数学描述上都具有相似性和一致性。<br />
===有效信息（EI）===<br />
有效信息（EI）最早由 Giulio Tononi 和 Olaf Sporns 提出，作为因果相互作用的一种度量，其中使用了系统的随机扰动，以超越统计依赖性&lt;ref name=&quot;:6&quot; /&gt;。人们在没有参考先前用法的情况下重新发现了这一概念，并将其称为 “因果特异性”&lt;ref&gt;Paul E. Griffiths, Arnaud Pocheville, Brett Calcott, Karola Stotz, Hyunju Kim, and Rob Knight. Measuring Causal Specificity. ''Philosophy of Science'', 82(4):529–555, 2015. Publisher: The University of Chicago Press.&lt;/ref&gt;。有效信息是系统所有可能因果关系中效应信息的期望值：<br />
<br />
&lt;math&gt;EI=\sum_{e\in E,c\in C}P(e,c)ei(c,e)&lt;/math&gt;<br />
<br />
作为因果关系的衡量标准，有效信息反映了系统中原因产生效应的有效程度（确定性和唯一性），以及从效应中识别原因的选择性&lt;ref&gt;Erik P. Hoel, L. Albantakis, and G. Tononi. Quantifying causal emergence shows that macro can beat micro.P''roceedings of the National Academy of Sciences'', 110(49):19790–19795, December 2013.&lt;/ref&gt;。有效信息是对 c 产生 e 的因果能力的评估--由效应信息衡量--适用于可能的因果之间的所有转换，同时考虑到对因果的最大熵干预分布。更简单地说，它是系统的确定性与简并性之间的非归一化差异。<br />
==因果基元的形式化==<br />
当我们讨论因果关系时，不应该简单地认为它只是一个简单的原因导致结果的关系。实际上，这种关系可以从两个不同的角度来看：一个是充分性，另一个是必要性。充分性是指一个原因是否总是能导致一个特定的结果，而必要性是指为了得到这个结果，是否需要这个特定的原因。我们可以把这两个概念看作是理解因果关系的基本元素，称为因果基元。在更广泛的意义上，充分性和必要性分别反映了因果关系之间的确定性和简并性。<br />
<br />
1.充分性：这里指的是原因&lt;math&gt;c&lt;/math&gt;对产生结果&lt;math&gt;e&lt;/math&gt;的充分程度。如果每当原因&lt;math&gt;c&lt;/math&gt;发生时，结果&lt;math&gt;e&lt;/math&gt;总是随之发生，那么我们可以说&lt;math&gt;c&lt;/math&gt;是产生&lt;math&gt;e&lt;/math&gt;的充分条件。换句话说，&lt;math&gt;c&lt;/math&gt;的存在足以确保&lt;math&gt;e&lt;/math&gt;的发生。充分性用表示公式为<br />
<br />
&lt;math&gt;suff (e, c) = P (e | c)<br />
&lt;/math&gt;<br />
<br />
2.必要性：这里指指原因&lt;math&gt;c&lt;/math&gt;对产生结果&lt;math&gt;e&lt;/math&gt;的必要性程度。如果只有通过&lt;math&gt;c&lt;/math&gt;才能产生&lt;math&gt;e&lt;/math&gt;，那么&lt;math&gt;c&lt;/math&gt;是产生&lt;math&gt;e&lt;/math&gt;的必要条件。这意味着没有&lt;math&gt;c&lt;/math&gt;，&lt;math&gt;e&lt;/math&gt;就不会发生。必要性用表示公式为<br />
<br />
&lt;math&gt;nec(e, c) = 1 – P (e | C\c)<br />
<br />
&lt;/math&gt;<br />
<br />
3.确定性：如果原因只有一个结果，即&lt;math&gt;P=1&lt;/math&gt;，则该熵项为零；如果原因具有完全随机的结果，则熵最大，即&lt;math&gt;log_2n&lt;/math&gt;，其中&lt;math&gt;n&lt;/math&gt;为所有可能结果的数量，用&lt;math&gt;H (e | c) &lt;/math&gt;表示原因导致结果的概率分布的熵，用公式表示为<br />
<br />
&lt;math&gt;\begin{aligned}H(e\mid c)=\sum_{e\in E}P(e\mid c)\log_2\frac{1}{P(e\mid c)}\end{aligned} &lt;/math&gt;<br />
<br />
因此，我们将原因&lt;math&gt;c&lt;/math&gt;的确定性定义为&lt;math&gt;log_2n - H (e | c) &lt;/math&gt;。我们将它做归一化处理，可以创建一个确定性系数&lt;math&gt;det &lt;/math&gt;，对于给定的原因，该系数的范围与充分性一样，在 0（完全随机）和 1（完全确定性）之间，公式为<br />
<br />
&lt;math&gt;det(c)=1-\frac{H(e\mid c)}{\log_2n} &lt;/math&gt;<br />
<br />
通过这个公式，我们可以定义一个单个因果转换的确定性系数<br />
<br />
&lt;math&gt;det(e,c)=1-\frac{\log_2\frac{1}{P(e|c)}}{\log_2n} &lt;/math&gt;<br />
<br />
以及系统级确定性系数<br />
<br />
&lt;math&gt;det=\sum\limits_{c\in C}P(c) det(c)=\sum\limits_{e\in E, c\in C}P(e,c) det(e,c)=1-\frac{\sum\limits_{c\in C}P(c) H(e\mid c)}{\log_2n} &lt;/math&gt;<br />
<br />
4.简并性：简并性是必要性的一种推广，如果所有可能的结果都有相同的概率，即没有任何一个结果比其他结果更有可能，那么简并性为零。如果某些特定的结果由更多的原因引起，那么这些特定的结果就更有可能发生，从而导致简并性增加。简并性的量化可以用一组原因&lt;math&gt;C&lt;/math&gt;导致&lt;math&gt;e&lt;/math&gt;发生的条件概率的熵来衡量，公式为<br />
<br />
&lt;math&gt;\begin{aligned}H(e\mid C)=\sum_{e\in E}P(e\mid C)\log_2\frac{1}{P(e\mid C)}\end{aligned}&lt;/math&gt;<br />
<br />
通过这个公式，我们可以定义一个单个因果效应的简并性系数<br />
<br />
&lt;math&gt;deg(e)=1-\frac{\log_2\frac{1}{P(e|C)}}{\log_2n}&lt;/math&gt;<br />
<br />
以及系统级简并性系数<br />
<br />
&lt;math&gt;deg=\sum_{e\in E}P(e\mid c) deg(e)=1-\frac{H(e\mid C)}{\log_{2}n}&lt;/math&gt;<br />
==因果度量方法中的因果基元==<br />
{| class=&quot;wikitable&quot;<br />
|+&lt;big&gt;各种因果度量方法及其形式化公式&lt;/big&gt;<br />
!序号<br />
!名称<br />
!形式化公式及其与因果基元的关系<br />
!备注<br />
|-<br />
|1<br />
|David Hume的恒常连结<br />
|&lt;math&gt;CS_{Galton}(e,c)=P(c)P(C\backslash c)[P(e\mid c)-P(e\mid C\backslash c)]=P(c)P(C\backslash c)[suff(e,c)+nec(e,c)-1]&lt;/math&gt;<br />
|<br />
|-<br />
|2<br />
|Eells 的因果关系度量是概率提升<br />
|&lt;math&gt;CS_{Eells}=P(e\mid c)-P(e\mid C\backslash c)=suff(e,c)+nec(e,c)-1&lt;/math&gt;<br />
|<br />
|-<br />
|3<br />
|Suppes将因果关系度量为概率提升<br />
|&lt;math&gt;CS_{Suppes}(c,e)=P(e\mid c)-P(e\mid C)=suff(e,c)-nec^{\dagger}(e)&lt;/math&gt;<br />
|<br />
|-<br />
|4<br />
|程氏的因果归因<br />
|&lt;math&gt;CS_{Cheng}(c,e)=\frac{P(e\mid c)-P(e\mid C\backslash c)}{1-P(e\mid C\backslash c)}=\frac{suff(e,c)+nec(e,c)-1}{nec(e,c)}&lt;/math&gt;<br />
|<br />
|-<br />
|5<br />
|Lewis的反事实因果理论<br />
|&lt;math&gt;CS_{Lewis}(c,e)=\frac{P(e\mid c)-P(e\mid C\backslash c)}{P(e\mid c)}=\frac{suff(e,c)+nec(e,c)-1}{suff(e,c)}&lt;/math&gt;<br />
|<br />
|-<br />
|6<br />
|Judea Pearl的因果关系测量方法<br />
|&lt;math&gt;\mathrm{PNS}=P(e\mid c)-P(e\mid C\backslash c)=suff(e,c)+nec(e,c)-1&lt;/math&gt;，<br />
&lt;math&gt;\mathrm{PN}=\frac{P(e\mid c)-P(e\mid C\backslash c)}{P(e\mid c)}=\frac{suff(e,c)+nec(e,c)-1}{suff(e,c)}&lt;/math&gt;，<br />
<br />
&lt;math&gt;\mathrm{PS}=\frac{P(e\mid c)-P(e\mid C\backslash c)}{1-P(e\mid C\backslash c)}=\frac{suff(e,c)+nec(e,c)-1}{nec(e,c)}&lt;/math&gt;<br />
|PNS对应关联层级，等价于&lt;math&gt;CS_{Eells}&lt;/math&gt;PN对应干预层级，等价于&lt;math&gt;CS_{Lewis}&lt;/math&gt;PS对应反事实层级，等价于&lt;math&gt;CS_{cheng}&lt;/math&gt;<br />
|-<br />
|7<br />
|最接近的可能世界因果关系<br />
|&lt;math&gt;CS_{Lewis CPW}=\frac{P(e\mid c)-P(e\mid\bar{c}_{CPW})}{P(e\mid c)}&lt;/math&gt;<br />
|其中&lt;math&gt;\bar{c}_{CPW}=\min_{c'}D_H(c,c')&lt;/math&gt; ，<br />
&lt;math&gt;D_H(c,c')&lt;/math&gt;为&lt;math&gt;c&lt;/math&gt;和&lt;math&gt;c'&lt;/math&gt;之间的汉明距离<br />
|-<br />
|8<br />
|位翻转措施<br />
|&lt;math&gt;CS_{bit-flip}(e,c)=\frac{1}{N}\sum_{i}^{N}\sum_{e^{\prime}\in E}P(e^{\prime}\mid c_{[i]})D_{H}(e,e^{\prime})&lt;/math&gt;<br />
|其中&lt;math&gt;c_{[i]}&lt;/math&gt;对应于第&lt;math&gt;i^{th}&lt;/math&gt;位被翻转的状态，<br />
（例如，如果 c = 000，则 c[3] = 001），<br />
<br />
&lt;math&gt;D_H(e,e')&lt;/math&gt;为&lt;math&gt;e&lt;/math&gt;和&lt;math&gt;e'&lt;/math&gt;之间的汉明距离<br />
|-<br />
|9<br />
|实际因果关系和效果信息<br />
|&lt;math&gt;ei(c,e)=\log_2\frac{P(e\mid c)}{P(e\mid C)}=\log_2n[det(e,c)-deg(c)]&lt;/math&gt;<br />
|<br />
|-<br />
|10<br />
|有效信息（EI）<br />
|&lt;math&gt;EI=\sum_{e\in E,c\in C}P(e,c)ei(c,e)=\log_{2}n[det-deg]&lt;/math&gt;<br />
|<br />
|}<br />
==总结==<br />
上表中的每一种因果度量方法，两个基元（充分性和必要性）或它们的广义形式（确定性和简并性性）都被明确地置于某种关系中，通常是差异、比率或权衡的关系。唯一缺乏因果基元明确基础的是比特翻转测量，但作为对扰动敏感性的测量，似乎有可能存在某种基础或关系（在这里并没有寻求分解）。我们并不是第一个指出因果关系有两个维度的人，例如，Judea Pearl 就说过： “显然，必须在因果解释的必要成分和充分成分之间取得某种平衡&quot;&lt;ref name=&quot;:5&quot; /&gt;。J. L. Mackie虽然没有提出因果关系强度的定量衡量标准，但他在提出原因应满足的 INUS 条件（Insufficient but Necessary part of an Unnecessary but Sufficient condition，简称INUS）时，考虑到了必要性和充分性两个方面，Mackie认为，一个真正的因果关系应该包含两个层面：首先，它必须是某个条件的一部分，这个条件本身足以导致结果发生，但这个条件不是唯一的，也就是说，还有其他可能的条件也可以导致同样的结果；其次，这个条件中的特定部分（即INUS条件）对于整个条件来说是必要的，但单独来看并不足以引起结果&lt;ref&gt;J. L. Mackie. Causes and Conditions. ''American Philosophical Quarterly'', 2(4):245–264, 1965. Publisher:University of Illinois Press.&lt;/ref&gt;。这些因果度量方法的相似性和一致性说明因果关系本身并不是一个原始概念，而是可以从充分性和必要性这两个维度进行分解，它们的广义形式分别是确定性和简并性。研究者们不再需要找到一个必须达成普遍共识的唯一因果关系衡量标准，而是可以通过关注这些相同的基本属性继续理解其他因果现象。<br />
&lt;references /&gt;</div>

## 马尔科夫链的粗粒化
[Read more](https://wiki.swarma.org/index.php?title=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E7%9A%84%E7%B2%97%E7%B2%92%E5%8C%96&diff=40149&oldid=40136)

Updated: 2024-12-06T07:56:55Z

<p><span dir="auto"><span class="autocomment">Lumpability</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月6日 (五) 07:56的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的2个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l101">第101行：</td>
<td class="diff-lineno" colspan="2">第101行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lumpable和non-lumpable的例子.png|缩略图|对lumpable和non-lumpable矩阵做粗粒化]]</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>[[文件:Lumpable和non-lumpable的例子.png|缩略图|对lumpable和non-lumpable矩阵做粗粒化<ins class="diffchange diffchange-inline">|替代=|600x600像素</ins>]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''''定义1'''''：'''Lumped process'''</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>'''''定义1'''''：'''Lumped process'''</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l145">第145行：</td>
<td class="diff-lineno" colspan="2">第145行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>不满足上述两个条件的，都不被定义为lumpable partition。也就是说，不是所有的lumped process都是lumpable的，即使他们的命名方式相似。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>不满足上述两个条件的，都不被定义为lumpable partition。也就是说，不是所有的lumped process都是lumpable的，即使他们的命名方式相似。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">从图2的lumpable和non-lumpable例子中，我们看到，lumpable矩阵是可以找到一个lumped process，而这个lumped process是满足马尔可夫性，且对所有初始状态都保持一致的。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div> </div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">而non-lumpable的矩阵，我们或许可以给它强制定义一个lumped process的TPM，比如&lt;math&gt; P_1' = \left ( \begin{array}{cc}</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">0.6 &amp; 0.4 \\</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">0.2 &amp; 0.8 \\</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">\end{array} \right )&lt;/math&gt;，但这个lumped process并不能对任何微观初始状态保持一致，只能对&lt;math&gt;s^{(t)} = \left [ \begin{array}{cc}1 &amp; 0 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;适用。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">而&lt;math&gt;s^{(t)} = \left [ \begin{array}{cc}0 &amp; 1 &amp; 0 &amp; 0 \end{array} \right ]&lt;/math&gt;不适用这个lumped process。它适用的是&lt;math&gt; P_2' = \left ( \begin{array}{cc}</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">0.5 &amp; 0.5 \\</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">0.2 &amp; 0.8 \\</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">\end{array} \right )&lt;/math&gt;。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">我们看到，对于这个state partition &lt;math&gt;A&lt;/math&gt;，马尔科夫矩阵有两个lumped process &lt;math&gt; P_1'&lt;/math&gt;和&lt;math&gt; P_2'&lt;/math&gt;，而它们各自只适用于一些微观初始状态(starting vector) &lt;math&gt; \pi &lt;/math&gt;，并不满足定义2中的条件，所以&lt;math&gt;A&lt;/math&gt;不是一个lumpable partition。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40136:rev-40149 -->
</table>

## 因果态
[Read more](https://wiki.swarma.org/index.php?title=%E5%9B%A0%E6%9E%9C%E6%80%81&diff=40146&oldid=40144)

Updated: 2024-12-05T11:09:40Z

<p></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月5日 (四) 11:09的版本</td>
				</tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l1">第1行：</td>
<td class="diff-lineno" colspan="2">第1行：</td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>在[[计算力学]]<del class="diffchange diffchange-inline">中，智能体对外部环境的建模过程中，需要找到一种有效的描述方式，使其可以把环境信息压缩成一个有限的状态空间，并存储于内部环境模型中。为了找到这种有效的描述方式，需要先定义一个叫做“因果态”的概念。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>在[[计算力学]]<ins class="diffchange diffchange-inline">中，智能体对外部环境的建模过程中，需要找到一种有效的描述方式，使其可以把环境信息压缩成一个有限的状态空间，并存储于内部环境模型中。为了找到这种有效的描述方式，需要先定义一个叫做“因果态”的概念&lt;ref&gt;Crutchfield, James P. &quot;The Calculi of Emergence: Computation, Dynamics, and Induction.&quot; Physica D: ''Nonlinear Phenomena'', vol. 75, no. 1-3, pp. 11-54, 1994. SFI-94-03-016. &lt;nowiki&gt;https://doi.org/10.1023/A:1010388907793&lt;/nowiki&gt;&lt;/ref&gt;。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">==因果态的定义==</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">智能体对环境的测量精度一般都是有限的，测量结果只能描述环境状态的投影。我们可以将环境从过去到未来的变化用一个离散的稳定[[随机过程]]描述，状态的取值空间则为双无限序列可数集合&lt;math&gt;\overleftrightarrow{S}=⋯s_{-2} s_{-1} s_0 s_1 s_2…&lt;/math&gt;，也就是说，一个状态指的是一个时间序列。基于当前的时刻&lt;math&gt;t&lt;/math&gt;，我们可以将&lt;math&gt;\overleftrightarrow{S}&lt;/math&gt;分为单侧前向序列&lt;math&gt;\overrightarrow{s_t}=s_t s_{t+1} s_{t+2} s_{t+3}…&lt;/math&gt;和单侧后向序列&lt;math&gt;\overleftarrow{s_t}=⋯s_{t-3} s_{t-2} s_{t-1} &lt;/math&gt;两个部分，所有可能的未来序列&lt;math&gt;\overrightarrow{s_t}&lt;/math&gt;形成的集合记作&lt;math&gt; \overrightarrow{S}&lt;/math&gt;，所有可能的历史序列&lt;math&gt;\overleftarrow{s_t}&lt;/math&gt;形成的集合记作&lt;math&gt; \overleftarrow{S}&lt;/math&gt;。某一个时刻的状态指的是截止到当前时刻的历史序列。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">通过某种划分（ partition），我们可以找到观测到的状态（可以称之为微观态）与智能体压缩后得到的隐空间上的状态（可以称为宏观态）之间的对应关系&lt;ref&gt;Shalizi, C. R., &amp; Crutchfield, J. P. &quot;Computational Mechanics: Pattern and Prediction, Structure and Simplicity.&quot; *''Journal of Statistical Physics''* 104 (2001): 817-879.&lt;/ref&gt;。划分为一种映射，&lt;math&gt; \eta{:}\overleftarrow{S}\mapsto\mathcal{R}&lt;/math&gt;，其中&lt;math&gt;\mathcal{R} &lt;/math&gt;是微观状态空间的子集的集合，要满足其元素彼此互斥，而且所有元素的并集等于&lt;math&gt; \overset{\leftarrow}{S}&lt;/math&gt;。通过划分操作得到的每个子集都可以被视为对应着一个宏观态。[[文件:划分示意图.jpg|居中|400x400像素|替代=|无框|链接=https://wiki.swarma.org/index.php/%E6%96%87%E4%BB%B6:%E5%88%92%E5%88%86%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg]]上图为某种划分的示意图，将集合&lt;math&gt; \overset{\leftarrow}{S}&lt;/math&gt;划分为某类状态&lt;math&gt; \mathcal{R}=\{\mathcal{R}_i:i=1,2,3,4\}&lt;/math&gt;，值得注意的是，&lt;math&gt; \mathcal{R}_i&lt;/math&gt;不必形成紧致集，也可以是康托集或其他更特殊的结构，上图为了示意清楚才这样画的。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">对于集合&lt;math&gt; \overset{\leftarrow}{S}&lt;/math&gt;的划分可以有很多种，若某一种划分能够在预测能力最强的同时又非常简洁，那么它肯定是最优的划分，我们把这种用最优的划分方法得到的状态称为[[因果态]]。因果态就是智能体对测量结果进行处理后，根据其内部模型（尤其是状态结构）识别出的斑图，并且这种斑图不随时间发生变化。形式化定义为：对于任意的时刻&lt;math&gt;t &lt;/math&gt; 和&lt;math&gt;t^{'} &lt;/math&gt;，给定过去状态&lt;math&gt; \overleftarrow{s_t}  &lt;/math&gt;的条件下，未来状态&lt;math&gt; \overrightarrow{s} &lt;/math&gt;的分布与给定过去状态&lt;math&gt; \overleftarrow{s_{t^{'}}} &lt;/math&gt;的条件下，未来状态&lt;math&gt; \overrightarrow{s} &lt;/math&gt;的分布相同。那么&lt;math&gt;t &lt;/math&gt; 和&lt;math&gt;t^{'} &lt;/math&gt;的关系就记作&lt;math&gt;t\sim t^{'} &lt;/math&gt;，“&lt;math&gt;∼ &lt;/math&gt; ” 表示由等效未来状态所引起的等价关系，也叫预测等价性（predictive equivalence），可以用公式表示为：&lt;math&gt;t\sim t^{'} \triangleq Pr(\overrightarrow{s}|\overleftarrow{s_t} )=Pr(\overrightarrow{s} |\overleftarrow{s_{t^{'}}} ) &lt;/math&gt;，若&lt;math&gt;t &lt;/math&gt; 和&lt;math&gt;t^{'} &lt;/math&gt;对未来状态预测的分布相同，则定义他们具有相同的因果态（casual state）。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">因果态的划分映射可以记作&lt;math&gt;\epsilon&lt;/math&gt;，公式为&lt;math&gt; \epsilon{:}\overleftarrow{S}\mapsto2^{\overset{\leftarrow}{S}}&lt;/math&gt;，其中&lt;math&gt; 2^{\overset{\leftarrow}{S}}&lt;/math&gt;是&lt;math&gt; \overleftarrow{S}&lt;/math&gt;的幂集。根据因果态的定义，则存在如下关系：&lt;math&gt;{ \epsilon(\stackrel{\leftarrow}{s})\equiv\{\stackrel{\leftarrow}{s}^{\prime}|\mathrm{P}(\overrightarrow{S}=\overrightarrow{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s})=\mathrm{P}(\overrightarrow{S}=\overrightarrow{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s}^{\prime})，\mathrm{for~all~}\overrightarrow{s}\in\overrightarrow{S},\stackrel{\leftarrow}{s}^{\prime}\in\stackrel{\leftarrow}{S}\} } &lt;/math&gt;，其中&lt;math&gt;\mathcal{S} &lt;/math&gt;为因果态的集合，&lt;math&gt;\stackrel{\leftarrow}{s} &lt;/math&gt;为历史序列的随机变量。[[文件:因果态的定义.jpg|居中|无框|400x400px|替代=|链接=https://wiki.swarma.org/index.php/%E6%96%87%E4%BB%B6:%E5%9B%A0%E6%9E%9C%E6%80%81%E7%9A%84%E5%AE%9A%E4%B9%89.jpg]]如上图所示，左侧的数字代表&lt;math&gt;t&lt;/math&gt;时刻的状态序列，右侧的箭头形状代表对未来状态预测的分布，可以观察到&lt;math&gt;t_9&lt;/math&gt;和&lt;math&gt;t_{13}&lt;/math&gt;时刻的箭头形状完全相同，说明它们对未来状态预测的分布相同，则处于相同的因果态；同样的道理，在&lt;math&gt;t_{11}&lt;/math&gt;时刻，它的箭头形状与&lt;math&gt;t_9&lt;/math&gt;和&lt;math&gt;t_{13}&lt;/math&gt;时刻不同，则处于不同的因果态。[[文件:木星大红斑.png|右|无框|225x225px|链接=https://wiki.swarma.org/index.php/%E6%96%87%E4%BB%B6:%E6%9C%A8%E6%98%9F%E5%A4%A7%E7%BA%A2%E6%96%91.png]]预测等价性（predictive equivalence）是计算内在涌现（简称内在计算，intrinsic computation）的核心思想&lt;ref&gt;Rupe, A., &amp; Crutchfield, J. P. (2024). On principles of emergent organization. ''Physics Reports''.&lt;nowiki&gt;https://doi.org/10.1016/j.physlet.2024.06.017&lt;/nowiki&gt;&lt;/ref&gt;，即系统的历史能够用来预测其未来行为的程度。通过构建预测模型，内在计算能够识别系统中的结构，并量化这些结构的复杂性和稳定性。它可以让我们能够将[[自组织]]视为系统中规律性和规则性的涌现，而这些规律性和规则性是系统在特定的初始条件和外部驱动下自发形成的。内在计算的一个重要应用是在理解从完全规则到完全无序之间的组织结构。比如，木星的大红斑是一个经典的自组织现象，其规模和稳定性无法通过简单的流体力学方程直接解释。然而，内在计算能够通过分析该现象的历史数据，构建出一个能够准确预测其未来行为的模型，从而揭示出其背后的自组织机制。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">==因果态的主要性质==</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">'''性质1（因果态具有最大预测性）'''：对于所有划分得到的状态&lt;math&gt;\mathcal{R} &lt;/math&gt;和正整数&lt;math&gt;L &lt;/math&gt;，都有&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]\geq H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;，&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;为&lt;math&gt;L &lt;/math&gt;个长度的未来序列集合，&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}] &lt;/math&gt;和&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;是&lt;math&gt;\stackrel{\rightarrow}{S}^L &lt;/math&gt;的[[条件熵]]。可以理解为因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的预测能力最强，证明过程如下：</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;math&gt;\epsilon(\stackrel{\leftarrow}{s})\equiv\{\stackrel{\leftarrow}{s}^{\prime}|\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s})=\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s}^{\prime}) &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;math&gt;\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s} |\mathcal{S}=\epsilon(\stackrel{\leftarrow}{s}))=\mathrm{P}(\stackrel{\rightarrow}{S}=\stackrel{\rightarrow}{s}\mid\stackrel{\leftarrow}{S}=\stackrel{\leftarrow}{s}) &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{S}]~=~H[\stackrel{\rightarrow}{S}^L|~\stackrel{\leftarrow}{S}] &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;math&gt;H[\stackrel{\to}{S}^L|\mathcal{R}] \geq H[\stackrel{\to}{S}^L|\stackrel{\leftarrow}{S}] &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]\geq H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">'''性质2（因果态具有最小统计复杂度）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;为满足性质1中不等式等号成立时划分得到的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;，都有&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;。可以理解为在相同预测能力的前提下，因果态集合&lt;math&gt;\mathcal{S} &lt;/math&gt;在划分得到的状态集合&lt;math&gt;\mathcal{R} &lt;/math&gt;的所有类型中，它的统计复杂度最小，证明过程如下：</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">对于任意的&lt;math&gt;\mathcal{R}&lt;/math&gt;，若&lt;math&gt;H[\stackrel{\rightarrow}{S}^L|\mathcal{R}]= H[\stackrel{\rightarrow}{S}^L|\mathcal{S}] &lt;/math&gt;，则存在函数&lt;math&gt;g &lt;/math&gt;使得&lt;math&gt;\mathcal{S}=g(\mathcal{R}) &lt;/math&gt;总是成立。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">根据&lt;math&gt;\mathcal{R} &lt;/math&gt;的定义可知，&lt;math&gt;H[\vec{S}^L|\mathcal{R}]&lt;LH[S] &lt;/math&gt;，则&lt;math&gt;H[f(X)]\leqslant H[X] &lt;/math&gt;。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">所以&lt;math&gt;H[S]=H[g(\hat{\mathcal{R}})]\leqslant H[\hat{\mathcal{R}}] &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">根据统计复杂度的定义可知，&lt;math&gt;C_\mu(\mathcal{R})\equiv H[\mathcal{R}] &lt;/math&gt;，则&lt;math&gt;C_\mu(\hat{\mathcal{R}})=H[\hat{\mathcal{R}}] &lt;/math&gt;。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">所以&lt;math&gt;C_\mu(\hat{\mathcal{R}})\geq C_\mu(\mathcal{S}) &lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">'''性质3（因果态具有最小随机性）'''：设&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;为满足性质1中不等式等号成立的状态，则对于所有的&lt;math&gt;\hat{\mathcal{R}} &lt;/math&gt;和&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;，都有&lt;math&gt;H[\hat{\mathcal{R}}^{\prime}|\hat{\mathcal{R}}]\geq H[\mathcal{S}^{\prime}|\mathcal{S}] &lt;/math&gt;，其中&lt;math&gt;\hat{\mathcal{R}}^{\prime} &lt;/math&gt;和&lt;math&gt;\mathcal{S}^{\prime} &lt;/math&gt;分别是该过程的下一时刻状态和下一时刻因果态。可以理解为在相同预测能力的前提下，因果态集合[math]\displaystyle{ \mathcal{S} }[/math]在划分得到的状态集合[math]\displaystyle{ \mathcal{R} }[/math]的所有类型中，它的随机性最小。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">用[[互信息]]的角度去理解的话，上式等价于&lt;math&gt;I(\mathcal{S}^{\prime};\mathcal{S})\geq I(\hat{\mathcal{R}}^{\prime};\hat{\mathcal{R}}) &lt;/math&gt;，可以理解为任意状态对它自己下一时刻的互信息中，其中因果态的互信息最大。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div> </div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">若想更深入的理解因果态的性质可以阅读Cosma Rohilla Shalizi 和James Crutchfield合写的一篇论文&lt;ref name=&quot;:4&quot;&gt;Shalizi, C. R.. &amp; Crutchfield, J. P. (2001). Computational Mechanics: Pattern and Prediction, Structure and Simplicity,Journal of Statistical Physics,104(3/4).817-879.&lt;/ref&gt;，里面有因果态更多的性质和对应的形式化证明过程。</ins></div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40144:rev-40146 -->
</table>

## 计算力学
[Read more](https://wiki.swarma.org/index.php?title=%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%AD%A6&diff=40145&oldid=40143)

Updated: 2024-12-05T10:45:08Z

<p><span dir="auto"><span class="autocomment">因果态的定义</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月5日 (四) 10:45的版本</td>
				</tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l91">第91行：</td>
<td class="diff-lineno" colspan="2">第91行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>相比之下，统计复杂度[math]\displaystyle{ C_μ(x) }[/math]剔除了通用图灵机在模拟随机比特时所花费的计算努力。统计复杂度的一个特征是，对于完全随机对象，有[math]\displaystyle{ C_μ(x)=0 }[/math]，如抛硬币产生的序列。同时对于简单的周期性过程，如[math]\displaystyle{ x=00000000…0 }[/math]时，也有[math]\displaystyle{ C_μ(x)=0 }[/math]。因此，统计复杂度的值对于（简单的）周期性过程和完全随机过程都很小。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>相比之下，统计复杂度[math]\displaystyle{ C_μ(x) }[/math]剔除了通用图灵机在模拟随机比特时所花费的计算努力。统计复杂度的一个特征是，对于完全随机对象，有[math]\displaystyle{ C_μ(x)=0 }[/math]，如抛硬币产生的序列。同时对于简单的周期性过程，如[math]\displaystyle{ x=00000000…0 }[/math]时，也有[math]\displaystyle{ C_μ(x)=0 }[/math]。因此，统计复杂度的值对于（简单的）周期性过程和完全随机过程都很小。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>下图展示了柯式复杂度和统计复杂度随着序列从简单周期性到完全随机的过程中的差异。如图(a)<del class="diffchange diffchange-inline">所示，柯式复杂度是过程中随机性的单调递增函数，是对[[信息源]]不可预测程度的度量，它可以通过香农熵率来衡量其随机性程度。相反，统计复杂度在两个极端点上均为零，并在中间达到最大值（见图</del>(b)）。它基于这样的观点：随机性在统计上是简单的，一个完全随机的过程具有零统计复杂度。周期性在统计上也是简单的，一个完全周期性过程具有较低的统计复杂度。复杂过程在这两个极端之间产生，并且是可预测机制和随机机制的混合，有中等程度随机性的数据具有最大的统计复杂度。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>下图展示了柯式复杂度和统计复杂度随着序列从简单周期性到完全随机的过程中的差异。如图(a)<ins class="diffchange diffchange-inline">所示，柯式复杂度是过程中随机性的单调递增函数。相反，统计复杂度在两个极端点上均为零，并在中间达到最大值（见图</ins>(b)）。它基于这样的观点：随机性在统计上是简单的，一个完全随机的过程具有零统计复杂度。周期性在统计上也是简单的，一个完全周期性过程具有较低的统计复杂度。复杂过程在这两个极端之间产生，并且是可预测机制和随机机制的混合，有中等程度随机性的数据具有最大的统计复杂度。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:复杂度比较.jpg|居中|无框|600x600像素|</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:复杂度比较.jpg|居中|无框|600x600像素|</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40143:rev-40145 -->
</table>

## 因果态
[Read more](https://wiki.swarma.org/index.php?title=%E5%9B%A0%E6%9E%9C%E6%80%81&diff=40144&oldid=0)

Updated: 2024-12-05T10:38:40Z

<p>建立内容为“在<a href="https://wiki.swarma.org/index.php/%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%AD%A6" title="计算力学">计算力学</a>中，智能体对外部环境的建模过程中，需要找到一种有效的描述方式，使其可以把环境信息压缩成一个有限…”的新页面</p>
<p><b>新页面</b></p><div>在[[计算力学]]中，智能体对外部环境的建模过程中，需要找到一种有效的描述方式，使其可以把环境信息压缩成一个有限的状态空间，并存储于内部环境模型中。为了找到这种有效的描述方式，需要先定义一个叫做“因果态”的概念。</div>

## 计算力学
[Read more](https://wiki.swarma.org/index.php?title=%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%AD%A6&diff=40143&oldid=40140)

Updated: 2024-12-05T10:33:21Z

<p><span dir="auto"><span class="autocomment">斑图重构机器</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月5日 (四) 10:33的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的1个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l13">第13行：</td>
<td class="diff-lineno" colspan="2">第13行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>有一些自然和社会现象非常引人入胜，但也很令人困惑，比如行为简单的蚂蚁可以形成复杂的社会，在没有控制中心的情况下自发产生特异化的社会分工&lt;ref&gt;B. Holldobler and E. O. Wilson. ''The Ants.'' Belknap Press of Harvard University Press, Cambridge, Massachusetts, 1990.&lt;/ref&gt;。 在没有领导者引导的情况下成群的鸟以步调一致的队形飞行，成群的鱼以连贯的阵列游动，突然一起转向&lt;ref&gt;C. W. Reynolds. Flocks, herds, and schools: A distributed behavioral model. ''Computer Graphics'', 21:25 – 34, 1987&lt;/ref&gt;。经济中商品的最佳定价似乎源于主体遵守当地的商业规则&lt;ref name=&quot;:0&quot;&gt;E. F. Fama. Efficient capital markets II. ''J.'' ''Finance'', 46:1575 – 1617, 1991&lt;/ref&gt;。这些现象中的全局协调是如何出现的？是否有共同的机制引导着这些不同现象的出现？在[[复杂系统 Complex Systems|复杂系统理论]]中把这类许多独立子系统相互作用后产生高度结构化的集体行为的现象称作[[涌现]]。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>有一些自然和社会现象非常引人入胜，但也很令人困惑，比如行为简单的蚂蚁可以形成复杂的社会，在没有控制中心的情况下自发产生特异化的社会分工&lt;ref&gt;B. Holldobler and E. O. Wilson. ''The Ants.'' Belknap Press of Harvard University Press, Cambridge, Massachusetts, 1990.&lt;/ref&gt;。 在没有领导者引导的情况下成群的鸟以步调一致的队形飞行，成群的鱼以连贯的阵列游动，突然一起转向&lt;ref&gt;C. W. Reynolds. Flocks, herds, and schools: A distributed behavioral model. ''Computer Graphics'', 21:25 – 34, 1987&lt;/ref&gt;。经济中商品的最佳定价似乎源于主体遵守当地的商业规则&lt;ref name=&quot;:0&quot;&gt;E. F. Fama. Efficient capital markets II. ''J.'' ''Finance'', 46:1575 – 1617, 1991&lt;/ref&gt;。这些现象中的全局协调是如何出现的？是否有共同的机制引导着这些不同现象的出现？在[[复杂系统 Complex Systems|复杂系统理论]]中把这类许多独立子系统相互作用后产生高度结构化的集体行为的现象称作[[涌现]]。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>目前对涌现的研究理论有[[基于有效信息的因果涌现理论]]、[[基于信息分解的因果涌现理论]]、[[基于可逆性的因果涌现理论]]，基于[[转移熵]]的动力学解耦理论&lt;ref&gt;Barnett L, Seth AK. Dynamical independence: discovering emergent macroscopic processes in complex dynamical systems. Physical Review E. 2023 Jul;108(1):014304.&lt;/ref&gt;、基于[[格兰杰因果关系|格兰杰因果]]的G-emergence理论&lt;ref&gt;A. K. Seth, Measuring emergence via nonlinear granger causality., in: alife, Vol. 2008, 2008, pp. 545–552.&lt;/ref&gt;<del class="diffchange diffchange-inline">等等。计算力学是基于统计复杂度对涌现的定量化研究理论，它提出的时间最早，虽然对涌现的的研究方法与上述理论均不同，但有很多研究思路是相似的，它定义的统计复杂度、因果态、斑图重构机器等概念对涌现的研究有很大启发和借鉴意义。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>目前对涌现的研究理论有[[基于有效信息的因果涌现理论]]、[[基于信息分解的因果涌现理论]]、[[基于可逆性的因果涌现理论]]，基于[[转移熵]]的动力学解耦理论&lt;ref&gt;Barnett L, Seth AK. Dynamical independence: discovering emergent macroscopic processes in complex dynamical systems. Physical Review E. 2023 Jul;108(1):014304.&lt;/ref&gt;、基于[[格兰杰因果关系|格兰杰因果]]的G-emergence理论&lt;ref&gt;A. K. Seth, Measuring emergence via nonlinear granger causality., in: alife, Vol. 2008, 2008, pp. 545–552.&lt;/ref&gt;<ins class="diffchange diffchange-inline">等等。计算力学是基于统计复杂度对涌现的定量化研究理论，它提出的时间最早，虽然对涌现的的研究方法与上述理论均不同，但有很多研究思路是相似的，它定义的统计复杂度、[[因果态]]、斑图重构机器等概念对涌现的研究有很大启发和借鉴意义。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 计算力学中的涌现 ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 计算力学中的涌现 ===</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l40">第40行：</td>
<td class="diff-lineno" colspan="2">第40行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>==模型的因果态和复杂度==</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>==模型的因果态和复杂度==</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">智能体需要一种有效的描述方式处理接受到的环境信息，使其可以把环境信息压缩成一个有限的状态空间，并存储于内部环境模型中。为了找到这种有效的描述方式，我们需要先定义一个叫做“因果态”的概念。</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">智能体需要一种有效的描述方式处理接受到的环境信息，使其可以把环境信息压缩成一个有限的状态空间，并存储于内部环境模型中。为了找到这种有效的描述方式，我们需要先定义一个叫做“[[因果态]]”的概念。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===因果态的定义===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===因果态的定义===</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l60">第60行：</td>
<td class="diff-lineno" colspan="2">第60行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===斑图重构机器===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===斑图重构机器===</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">前面给出了[[因果态]]的定义，接下来讨论一个智能体是如何从观测到的时间序列数据中，自动地发现因果态呢？为了解决这个问题，计算力学建立了名为斑图重构机器（ϵ</del>-machine）的模型，其中[[因果态]]所对应的划分映射被记为&lt;math&gt;\epsilon&lt;/math&gt;。它可以重构测量结果中的序列，去除随机噪声后识别其中的因果态。它的形式化定义可以用公式表示为&lt;math&gt;M=(\mathcal{S},T)&lt;/math&gt;，&lt;math&gt;T&lt;/math&gt;为状态到状态映射的集合，满足&lt;math&gt;S_{t+1}=TS_t&lt;/math&gt;，其中&lt;math&gt;S_t&lt;/math&gt;为集合&lt;math&gt;\mathcal{S} &lt;/math&gt;中的任意一个因果态，类似于一个宏观态。&lt;math&gt;T_{ij}^{\left ( s \right )}&lt;/math&gt;为两个因果态&lt;math&gt;S_i&lt;/math&gt;和&lt;math&gt;S_j&lt;/math&gt;之间的因果态转移概率映射，&lt;math&gt;T_{ij}^{(s)}\equiv\mathrm{P}(\mathcal{S}'=\mathcal{S}_j,\stackrel{\to}{S}^1=s|\mathcal{S}=\mathcal{S}_i)&lt;/math&gt;，&lt;math&gt;T&lt;/math&gt;类似于一个粗粒化后的[[宏观动力学]]。每个[math]\displaystyle{ \mathcal{S} }[/math]都对应一个&lt;math&gt;\epsilon&lt;/math&gt;映射，它和&lt;math&gt;T&lt;/math&gt;函数一起组成一个有序对&lt;math&gt;\left \{ \epsilon,T \right \}&lt;/math&gt;。后文“模型的重构”一节中会介绍，智能体的内在模型会根据观测到的新数据，动态更新&lt;math&gt;\epsilon&lt;/math&gt;映射和&lt;math&gt;T&lt;/math&gt;函数。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">前面给出了因果态的定义，接下来讨论一个智能体是如何从观测到的时间序列数据中，自动地发现因果态呢？为了解决这个问题，计算力学建立了名为斑图重构机器（ϵ</ins>-machine）的模型，其中[[因果态]]所对应的划分映射被记为&lt;math&gt;\epsilon&lt;/math&gt;。它可以重构测量结果中的序列，去除随机噪声后识别其中的因果态。它的形式化定义可以用公式表示为&lt;math&gt;M=(\mathcal{S},T)&lt;/math&gt;，&lt;math&gt;T&lt;/math&gt;为状态到状态映射的集合，满足&lt;math&gt;S_{t+1}=TS_t&lt;/math&gt;，其中&lt;math&gt;S_t&lt;/math&gt;为集合&lt;math&gt;\mathcal{S} &lt;/math&gt;中的任意一个因果态，类似于一个宏观态。&lt;math&gt;T_{ij}^{\left ( s \right )}&lt;/math&gt;为两个因果态&lt;math&gt;S_i&lt;/math&gt;和&lt;math&gt;S_j&lt;/math&gt;之间的因果态转移概率映射，&lt;math&gt;T_{ij}^{(s)}\equiv\mathrm{P}(\mathcal{S}'=\mathcal{S}_j,\stackrel{\to}{S}^1=s|\mathcal{S}=\mathcal{S}_i)&lt;/math&gt;，&lt;math&gt;T&lt;/math&gt;类似于一个粗粒化后的[[宏观动力学]]。每个[math]\displaystyle{ \mathcal{S} }[/math]都对应一个&lt;math&gt;\epsilon&lt;/math&gt;映射，它和&lt;math&gt;T&lt;/math&gt;函数一起组成一个有序对&lt;math&gt;\left \{ \epsilon,T \right \}&lt;/math&gt;。后文“模型的重构”一节中会介绍，智能体的内在模型会根据观测到的新数据，动态更新&lt;math&gt;\epsilon&lt;/math&gt;映射和&lt;math&gt;T&lt;/math&gt;函数。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== '''统计复杂度''' ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== '''统计复杂度''' ===</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l177">第177行：</td>
<td class="diff-lineno" colspan="2">第177行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 逻辑斯谛映射 ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 逻辑斯谛映射 ===</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">接下来将采用具体的方法来演示如何将计算力学的理论应用于实际案例</del>&lt;ref name=&quot;:1&quot;&gt;James P. Crutchfield. The Calculi of Emergence: Computation, Dynamics, and Induction. SFI 94-03-016. 1994&lt;/ref&gt;，要演示的是混沌动力学中的[[Logistic映射|逻辑斯谛映射]](logistic map)，特别是其周期倍增的混沌路径。用于重建模型的数据流来自逻辑斯谛映射的轨迹，轨迹是通过迭代映射&lt;math&gt;x_{n+1}=f(x_n)&lt;/math&gt;生成的，迭代函数为&lt;math&gt;f(x) = rx(1-x)&lt;/math&gt;，其中非线性参数&lt;math&gt;\begin{matrix}r&amp;\in&amp;[0,4]\end{matrix}&lt;/math&gt;，初始条件&lt;math&gt;x_0\in[0,1]&lt;/math&gt;，迭代函数的最大值出现在&lt;math&gt;x_c = \frac12&lt;/math&gt;。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">接下来将采用模型重构的算法来演示如何将计算力学的理论应用于实际案例</ins>&lt;ref name=&quot;:1&quot;&gt;James P. Crutchfield. The Calculi of Emergence: Computation, Dynamics, and Induction. SFI 94-03-016. 1994&lt;/ref&gt;，要演示的是混沌动力学中的[[Logistic映射|逻辑斯谛映射]](logistic map)，特别是其周期倍增的混沌路径。用于重建模型的数据流来自逻辑斯谛映射的轨迹，轨迹是通过迭代映射&lt;math&gt;x_{n+1}=f(x_n)&lt;/math&gt;生成的，迭代函数为&lt;math&gt;f(x) = rx(1-x)&lt;/math&gt;，其中非线性参数&lt;math&gt;\begin{matrix}r&amp;\in&amp;[0,4]\end{matrix}&lt;/math&gt;，初始条件&lt;math&gt;x_0\in[0,1]&lt;/math&gt;，迭代函数的最大值出现在&lt;math&gt;x_c = \frac12&lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:逻辑斯谛曲线.jpg|居中|无框|300x300px|替代=]]</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>[[文件:逻辑斯谛曲线.jpg|居中|无框|300x300px|替代=]]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>上图为迭代函数&lt;math&gt;f(x) = rx(1-x)&lt;/math&gt;中&lt;math&gt;r&lt;/math&gt;与&lt;math&gt;x&lt;/math&gt;的关系图，当&lt;math&gt;r＜3.5699...&lt;/math&gt;时函数存在倍周期现象，当&lt;math&gt;r＞3.5699...&lt;/math&gt;时会出现混沌现象。由于观察者观测的精细程度有限，若要识别混沌中的有序结构，就需要对&lt;math&gt;x&lt;/math&gt;进行粗粒化操作，方法是通过二元分割观察轨迹&lt;math&gt;\mathbf{x}=x_0x_1x_2x_3\ldots &lt;/math&gt; ，将其转换为离散序列&lt;math&gt;\mathcal{P}=\{x_n\in[0,x_c)\Rightarrow s=0,x_n\in[x_c,1]\Rightarrow s=1\} &lt;/math&gt;，这种划分是“生成”的，这意味着足够长的二进制序列来自任意小的初始条件间隔。因此，可以使用粗粒化的观测&lt;math&gt;\mathcal{P} &lt;/math&gt;来研究逻辑斯谛映射中的信息处理。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>上图为迭代函数&lt;math&gt;f(x) = rx(1-x)&lt;/math&gt;中&lt;math&gt;r&lt;/math&gt;与&lt;math&gt;x&lt;/math&gt;的关系图，当&lt;math&gt;r＜3.5699...&lt;/math&gt;时函数存在倍周期现象，当&lt;math&gt;r＞3.5699...&lt;/math&gt;时会出现混沌现象。由于观察者观测的精细程度有限，若要识别混沌中的有序结构，就需要对&lt;math&gt;x&lt;/math&gt;进行粗粒化操作，方法是通过二元分割观察轨迹&lt;math&gt;\mathbf{x}=x_0x_1x_2x_3\ldots &lt;/math&gt; ，将其转换为离散序列&lt;math&gt;\mathcal{P}=\{x_n\in[0,x_c)\Rightarrow s=0,x_n\in[x_c,1]\Rightarrow s=1\} &lt;/math&gt;，这种划分是“生成”的，这意味着足够长的二进制序列来自任意小的初始条件间隔。因此，可以使用粗粒化的观测&lt;math&gt;\mathcal{P} &lt;/math&gt;来研究逻辑斯谛映射中的信息处理。</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l188">第188行：</td>
<td class="diff-lineno" colspan="2">第188行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 模型升级 ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 模型升级 ===</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">[[文件:机器升级状态结构图.jpg|居中|无框|1000x1000像素]]</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins class="diffchange diffchange-inline">下面三张图展示了模型重构进化的一种路径。下图（a）为逻辑斯谛映射在&lt;math&gt;H_c &lt;/math&gt;（</ins>&lt;math&gt;r=3.5699...&lt;/math&gt;<ins class="diffchange diffchange-inline">）处，序列长度</ins>&lt;math&gt;L=16 &lt;/math&gt;<ins class="diffchange diffchange-inline">时用斑图重构机器重构后的47个状态路径图。图中每条闭合的链路长度都是16步，例如初始圆圈-1-3-5-9-12-16-19-21-23-27-31-35-39-41-43-45这条路径，它的总步数为16，每两步之间的数字是通过二元分割生成的采样结果，每个分支代表它经历了一次伯努利随机过程。但是图（a）捕捉到的规律并不明显，我们将它进行一个简单的转换，用每两步之间的数字组成的序列替换机器中未分支的路径后就是图（b），图（b）中的分支状态相当有规律，更进一步将图（b）升级为用字符生成器来描述增长的规律性，如图（c）所示，有限自动机有两种状态（原有类型用圆圈表示，新类型用方块表示）和两个寄存器 </ins>A 和 B，A 和 B用于保存二进制字符串，初始状态 A 中保存的是0，B中保存的是1，B'表示对保存在B中的字符串的最后一位取反。观察一下图（b）就会发现字符串操作可以通过将 A 的内容副本附加到 B 上，并用 B 的内容的两个副本替换 A 的内容来描述。这些字符串在方块处迭代，迭代式表示为 A→BB 和 B→BA。例如图（c）中从起始点-2-4-7-13这条链路，起始字符是1，可以用B描述，在4-7处发生变化，用B'描述，在7处产生了新的类型，B中字符变为10，在这B'就是11，依此类推，就得到了图（c）。显然（c）的方式比（a）的方式更加节省计算资源，它的描述能力也更强。<ins class="diffchange diffchange-inline">[[文件:机器升级状态结构图.jpg|居中|无框|1000x1000像素]]</ins></div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del class="diffchange diffchange-inline">以上三张图展示了模型重构进化的一种路径。上图（a）为逻辑斯谛映射在</del>&lt;math&gt;r=3.5699...&lt;/math&gt;<del class="diffchange diffchange-inline">处，序列长度</del>&lt;math&gt;L=16 &lt;/math&gt;<del class="diffchange diffchange-inline">时用斑图重构机器重构后的47个状态路径图。它捕捉到的规律并不明显，我们将它进行一个简单的转换，用相应的序列替换机器中未分支的路径后就是图（b），图（b）中的分支状态相当有规律，更进一步将图（b）升级为用字符生成器来描述机器增长的规律性，如图（c）所示，有限自动机有两种状态（原有类型用圆圈表示，新类型用方块表示）和两个寄存器 </del>A 和 B，A 和 B用于保存二进制字符串，初始状态 A 中保存的是0，B中保存的是1，B'表示对保存在B中的字符串的最后一位取反。观察一下图（b）就会发现字符串操作可以通过将 A 的内容副本附加到 B 上，并用 B 的内容的两个副本替换 A 的内容来描述。这些字符串在方块处迭代，迭代式表示为 A→BB 和 B→BA。例如图（c）中从起始点-2-4-7-13这条链路，起始字符是1，可以用B描述，在4-7处发生变化，用B'描述，在7处产生了新的类型，B中字符变为10，在这B'就是11，依此类推，就得到了图（c）。显然（c）的方式比（a）的方式更加节省计算资源，它的描述能力也更强。</div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>== 计算力学与因果涌现理论的相似性 ==</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>== 计算力学与因果涌现理论的相似性 ==</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40140:rev-40143 -->
</table>

## Causal Emergence
[Read more](https://wiki.swarma.org/index.php?title=Causal_Emergence&diff=40141&oldid=40070)

Updated: 2024-12-05T04:03:56Z

<p><span dir="auto"><span class="autocomment">Ambiguity</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月5日 (四) 04:03的版本</td>
				</tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l751">第751行：</td>
<td class="diff-lineno" colspan="2">第751行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>First of all, &lt;ref name=&quot;Eberhardt&quot;/&gt; points out that if there are no constraints on the coarse-graining scheme, ambiguity may arise when coarse-graining the transition probability matrix (TPM) (merging states and adding up probabilities). For example, when the two row vectors in the TPM corresponding to the two states to be merged are very dissimilar, forcibly merging them (for example, by taking the average) will cause ambiguity. This ambiguity is mainly manifested in the question of what exactly the intervention on the merged macroscopic state means<del class="diffchange diffchange-inline">. </del>Since the row vectors are dissimilar, the intervention on the merged macroscopic state cannot be simply reduced to the intervention on the microscopic states. If the intervention on the macroscopic state is forcibly converted into the intervention on the microscopic states by taking the average, the differences between the microscopic states are ignored. At the same time, new contradictory problems of non-commutativity will also be triggered.</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>First of all, &lt;ref name=&quot;Eberhardt&quot;/&gt; points out that if there are no constraints on the coarse-graining scheme, ambiguity may arise when coarse-graining the transition probability matrix (TPM) (merging states and adding up probabilities). For example, when the two row vectors in the TPM corresponding to the two states to be merged are very dissimilar, forcibly merging them (for example, by taking the average) will cause ambiguity. This ambiguity is mainly manifested in the question of what exactly the intervention on the merged macroscopic state means<ins class="diffchange diffchange-inline">? </ins>Since the row vectors are dissimilar, the intervention on the merged macroscopic state cannot be simply reduced to the intervention on the microscopic states. If the intervention on the macroscopic state is forcibly converted into the intervention on the microscopic states by taking the average, the differences between the microscopic states are ignored. At the same time, new contradictory problems of non-commutativity will also be triggered.</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div> </div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>====Non-commutativity====</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>====Non-commutativity====</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40070:rev-40141 -->
</table>

## 计算力学
[Read more](https://wiki.swarma.org/index.php?title=%E8%AE%A1%E7%AE%97%E5%8A%9B%E5%AD%A6&diff=40140&oldid=40098)

Updated: 2024-12-05T03:30:59Z

<p><span dir="auto"><span class="autocomment">香农熵率</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月5日 (四) 03:30的版本</td>
				</tr><tr><td class="diff-multi" colspan="4" lang="zh-Hans-CN">（未显示同一用户的2个中间版本）</td></tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l96">第96行：</td>
<td class="diff-lineno" colspan="2">第96行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>]]</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>]]</div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">=== 香农熵率 ===</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">上文中提到的随机性可以用香农熵率（Shannon Entropy Rate）来度量，香农熵率是信息论中的一个概念，它是[[香农熵]]的扩展，主要用于描述时间序列（如[[随机过程]]）的平均信息量。香农熵率是信息不确定性程度的归一化指标，信息的不确定性越高，香农熵率越大。如果环境信息生成的离散符号序列记作[math]\displaystyle{ s^L }[/math] ，[math]\displaystyle{ L }[/math]为序列的长度，香农熵率记作[math]\displaystyle{ h_μ }[/math]，它与柯式复杂度[math]\displaystyle{ K(x) }[/math]的关系为：</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">\frac{K\left(s^{L}\right)}{L}\underset{L\to\infty}{\operatorname*{\operatorname*{\operatorname*{\rightarrow}}}}h_{\mu} ,</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">在这里，香农熵率就可以定义为：</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">h_\mu=\lim_{L\to\infty}\frac{H(\Pr(s^L))}L </ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">&lt;/math&gt;</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">其中&lt;math&gt; \Pr(s^L)&lt;/math&gt;是[math]\displaystyle{ s^L }[/math]的边际分布，[math]\displaystyle{ H }[/math]是香农熵，也就是[[自信息]]的平均值，在建模框架中，[math]\displaystyle{ h_μ }[/math]可以解释为智能体在预测序列[math]\displaystyle{ s^L }[/math]的后续符号时的误差率。</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">上文中我们介绍了柯式复杂度、统计复杂度和香农熵率这三个与复杂性相关的指标，其实这三者之间存在一个近似关系，可以用公式表示为：</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">[math]\displaystyle{ K(s^L )≈C_μ (s^L )+h_μ L }[/math]</ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;"></ins></div></td></tr>
<tr><td colspan="2"> </td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div><ins style="font-weight: bold; text-decoration: none;">如果在已确定描述语言（程序）的情况下，柯式复杂度[math]\displaystyle{ K(s^L ) }[/math]可以理解为描述[math]\displaystyle{ s^L }[/math]所用的总信息量。[math]\displaystyle{ h_μ L }[/math]为允许损失的信息量。统计复杂度[math]\displaystyle{ C_μ (s^L ) }[/math]可以理解为允许存在误差率[math]\displaystyle{ h_μ }[/math]的情况下，描述[math]\displaystyle{ s^L }[/math]所用的最少信息量。</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 因果态的主要性质 ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 因果态的主要性质 ===</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l131">第131行：</td>
<td class="diff-lineno" colspan="2">第151行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>Simplicity,Journal of Statistical Physics,104(3/4).817-879.&lt;/ref&gt;，里面有因果态更多的性质和对应的形式化证明过程。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>Simplicity,Journal of Statistical Physics,104(3/4).817-879.&lt;/ref&gt;，里面有因果态更多的性质和对应的形式化证明过程。</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">=== 香农熵率 ===</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">香农熵率（Shannon Entropy Rate）是信息论中的一个概念，通常用来衡量一个[[信源]]或[[随机过程]]在单位时间内传输的[[信息量]]，或者说是该信源的不确定性和复杂性的度量。它是香农熵的扩展，主要用于描述时间序列（如随机过程）的平均信息量。如果待测对象是由信源（例如[[马尔可夫链]]）生成的离散符号序列[math]\displaystyle{ s^L }[/math] ，[math]\displaystyle{ L }[/math]为序列的长度，香农熵率为[math]\displaystyle{ h_μ }[/math]，它与柯式复杂度[math]\displaystyle{ K(x) }[/math]的关系为：</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">\frac{K\left(s^{L}\right)}{L}\underset{L\to\infty}{\operatorname*{\operatorname*{\operatorname*{\rightarrow}}}}h_{\mu} ,</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;/math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">在这里，香农熵率就可以定义为：</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">h_\mu=\lim_{L\to\infty}\frac{H(\Pr(s^L))}L </del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">&lt;/math&gt;</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">其中&lt;math&gt; \Pr(s^L)&lt;/math&gt;是[math]\displaystyle{ s^L }[/math]的边际分布，[math]\displaystyle{ H }[/math]是[[Shannon熵]]，也就是[[自信息]]的平均值，在建模框架中，[math]\displaystyle{ h_μ }[/math]是信息不确定性程度的归一化指标，信息的不确定性越高，香农熵率越大，在这里可以解释为智能体在预测序列[math]\displaystyle{ s^L }[/math]的后续符号时的误差率。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">上文中我们介绍了柯式复杂度、统计复杂度和香农熵率这三个与复杂性相关的指标，其实这三者之间存在一个近似关系，可以用公式表示为：</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">[math]\displaystyle{ K(s^L )≈C_μ (s^L )+h_μ L }[/math]</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">如果在已确定描述语言（程序）的情况下，柯式复杂度[math]\displaystyle{ K(s^L ) }[/math]可以理解为描述[math]\displaystyle{ s^L }[/math]所用的总信息量。[math]\displaystyle{ h_μ L }[/math]为允许损失的信息量。统计复杂度[math]\displaystyle{ C_μ (s^L ) }[/math]可以理解为允许存在误差率[math]\displaystyle{ h_μ }[/math]的情况下，描述[math]\displaystyle{ s^L }[/math]所用的最少信息量。</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;"></del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div><del style="font-weight: bold; text-decoration: none;">==模型的重构==</del></div></td><td colspan="2"> </td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===模型重构===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>===模型重构===</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l187">第187行：</td>
<td class="diff-lineno" colspan="2">第185行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>上图（a）为逻辑斯谛映射中统计复杂度&lt;math&gt;C_μ  &lt;/math&gt;与香农熵率&lt;math&gt;H(L)/L &lt;/math&gt;的关系，三角形表示&lt;math&gt;(C_μ ,H(L)/L) &lt;/math&gt;的大概位置，对应非线性参数&lt;math&gt;r&lt;/math&gt;的 193 个取值，其中子序列长度&lt;math&gt;L=16 &lt;/math&gt;，覆盖部分实验数据的粗实线是&lt;math&gt;C_μ =0 &lt;/math&gt;时对&lt;math&gt;H(L)/L &lt;/math&gt;得出的分析曲线。本图表现两个重要特征。第一个特征是熵的极值导致零复杂度，也就是说在&lt;math&gt;H(L)/L=0 &lt;/math&gt;处最简单的周期过程和在&lt;math&gt;H(L)/L=1 &lt;/math&gt;处最随机的过程在统计上都是简单的，它们都具有零复杂度，因为它们是由具有单一状态的斑图重构机器描述的。第二个特征是在两个极端情况之间，过程明显更为复杂，在临界熵值&lt;math&gt;H_c &lt;/math&gt;附近出现明显峰值（此处&lt;math&gt;r=3.5699...&lt;/math&gt;），&lt;math&gt;H(L)/L &lt;/math&gt;小于&lt;math&gt;H_c &lt;/math&gt;时数据集在呈周期性（包括在混沌区域也呈周期性的参数）的参数下产生，大于&lt;math&gt;H_c &lt;/math&gt;时数据集在混沌的参数下产生。本图可以对照统计复杂度小节中的图（b）理解。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>上图（a）为逻辑斯谛映射中统计复杂度&lt;math&gt;C_μ  &lt;/math&gt;与香农熵率&lt;math&gt;H(L)/L &lt;/math&gt;的关系，三角形表示&lt;math&gt;(C_μ ,H(L)/L) &lt;/math&gt;的大概位置，对应非线性参数&lt;math&gt;r&lt;/math&gt;的 193 个取值，其中子序列长度&lt;math&gt;L=16 &lt;/math&gt;，覆盖部分实验数据的粗实线是&lt;math&gt;C_μ =0 &lt;/math&gt;时对&lt;math&gt;H(L)/L &lt;/math&gt;得出的分析曲线。本图表现两个重要特征。第一个特征是熵的极值导致零复杂度，也就是说在&lt;math&gt;H(L)/L=0 &lt;/math&gt;处最简单的周期过程和在&lt;math&gt;H(L)/L=1 &lt;/math&gt;处最随机的过程在统计上都是简单的，它们都具有零复杂度，因为它们是由具有单一状态的斑图重构机器描述的。第二个特征是在两个极端情况之间，过程明显更为复杂，在临界熵值&lt;math&gt;H_c &lt;/math&gt;附近出现明显峰值（此处&lt;math&gt;r=3.5699...&lt;/math&gt;），&lt;math&gt;H(L)/L &lt;/math&gt;小于&lt;math&gt;H_c &lt;/math&gt;时数据集在呈周期性（包括在混沌区域也呈周期性的参数）的参数下产生，大于&lt;math&gt;H_c &lt;/math&gt;时数据集在混沌的参数下产生。本图可以对照统计复杂度小节中的图（b）理解。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>上图（b）为逻辑斯谛映射中在&lt;math&gt;r=3.5699...&lt;/math&gt;<del class="diffchange diffchange-inline">处，</del>&lt;math&gt;L &lt;/math&gt;与隐状态数量&lt;math&gt;\left|\mathbf{V}\right| &lt;/math&gt;的关系，序列的长度&lt;math&gt;L=64 &lt;/math&gt;时，&lt;math&gt;\left|\mathbf{V}\right|=196 &lt;/math&gt;，从图中可以看出，随着&lt;math&gt;L &lt;/math&gt;的增长，&lt;math&gt;\left|\mathbf{V}\right| &lt;/math&gt;的值是发散的，若要用有限的&lt;math&gt;L &lt;/math&gt;来描述&lt;math&gt;\left|\mathbf{V}\right| &lt;/math&gt;，就需要将模型进行重构，升级为描述能力更强的模型。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>上图（b）为逻辑斯谛映射中在<ins class="diffchange diffchange-inline">&lt;math&gt;H_c &lt;/math&gt;（</ins>&lt;math&gt;r=3.5699...&lt;/math&gt;<ins class="diffchange diffchange-inline">）处，</ins>&lt;math&gt;L &lt;/math&gt;与隐状态数量&lt;math&gt;\left|\mathbf{V}\right| &lt;/math&gt;的关系，序列的长度&lt;math&gt;L=64 &lt;/math&gt;时，&lt;math&gt;\left|\mathbf{V}\right|=196 &lt;/math&gt;，从图中可以看出，随着&lt;math&gt;L &lt;/math&gt;的增长，&lt;math&gt;\left|\mathbf{V}\right| &lt;/math&gt;的值是发散的，若要用有限的&lt;math&gt;L &lt;/math&gt;来描述&lt;math&gt;\left|\mathbf{V}\right| &lt;/math&gt;，就需要将模型进行重构，升级为描述能力更强的模型。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 模型升级 ===</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>=== 模型升级 ===</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40098:rev-40140 -->
</table>

## 基于有效信息的因果涌现理论
[Read more](https://wiki.swarma.org/index.php?title=%E5%9F%BA%E4%BA%8E%E6%9C%89%E6%95%88%E4%BF%A1%E6%81%AF%E7%9A%84%E5%9B%A0%E6%9E%9C%E6%B6%8C%E7%8E%B0%E7%90%86%E8%AE%BA&diff=40137&oldid=40037)

Updated: 2024-12-05T01:55:18Z

<p><span dir="auto"><span class="autocomment">代码</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月5日 (四) 01:55的版本</td>
				</tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l464">第464行：</td>
<td class="diff-lineno" colspan="2">第464行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>     return micro_ei, macro_ei, S_m, S_M</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>     return micro_ei, macro_ei, S_m, S_M</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div># <del class="diffchange diffchange-inline">Example：</del></div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div># <ins class="diffchange diffchange-inline">Example：状态空间计算实例</ins></div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>micro_tpm = torch.tensor([[1/3, 1/3, 1/3, 0], [1/3, 1/3, 1/3, 0], [1/3, 1/3, 1/3, 0], [0, 0, 0, 1]])</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>micro_tpm = torch.tensor([[1/3, 1/3, 1/3, 0], [1/3, 1/3, 1/3, 0], [1/3, 1/3, 1/3, 0], [0, 0, 0, 1]])</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>group = [(0, 1, 2), (3,)]</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>group = [(0, 1, 2), (3,)]</div></td></tr>
<tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l476">第476行：</td>
<td class="diff-lineno" colspan="2">第476行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>elem_group = [(0, 1), (2, 3)]</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>elem_group = [(0, 1), (2, 3)]</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>mech_group = {'00': '0', '01': '0', '10': '0', '11': '1'}</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>mech_group = {'00': '0', '01': '0', '10': '0', '11': '1'}</div></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>micro_ei, macro_ei = calc_bn_ei(micro_mech, micro, edges, elem_group, mech_group)</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>micro_ei, macro_ei<ins class="diffchange diffchange-inline">, S_m, S_M </ins>= calc_bn_ei(micro_mech, micro, edges, elem_group, mech_group)</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>CE = macro_ei - micro_ei</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>CE = macro_ei - micro_ei</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;/syntaxhighlight&gt;</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>&lt;/syntaxhighlight&gt;</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40037:rev-40137 -->
</table>

## 马尔科夫链的粗粒化
[Read more](https://wiki.swarma.org/index.php?title=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E7%9A%84%E7%B2%97%E7%B2%92%E5%8C%96&diff=40136&oldid=40135)

Updated: 2024-12-04T15:04:10Z

<p><span dir="auto"><span class="autocomment">Lumpability</span></span></p>
<table class="diff diff-contentalign-left diff-editfont-monospace">
				<col class="diff-marker" />
				<col class="diff-content" />
				<col class="diff-marker" />
				<col class="diff-content" />
				<tr class="diff-title" lang="zh-Hans-CN">
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">←上一版本</td>
				<td colspan="2" style="background-color: #fff; color: #202122; text-align: center;">2024年12月4日 (三) 15:04的版本</td>
				</tr><tr><td class="diff-lineno" colspan="2" id="mw-diff-left-l98">第98行：</td>
<td class="diff-lineno" colspan="2">第98行：</td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>首先定义&lt;math&gt;s^{(t)}&lt;/math&gt;表示系统在&lt;math&gt;t&lt;/math&gt;时刻的微观状态，微观状态空间为&lt;math&gt;S=\{s_1, s_2, ... ,s_n\}&lt;/math&gt;。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>首先定义&lt;math&gt;s^{(t)}&lt;/math&gt;表示系统在&lt;math&gt;t&lt;/math&gt;时刻的微观状态，微观状态空间为&lt;math&gt;S=\{s_1, s_2, ... ,s_n\}&lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker">−</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #ffe49c; vertical-align: top; white-space: pre-wrap;"><div>给定一个任意state partition &lt;math&gt;A=\{A_1, A_2, ... ,A_r\}&lt;/math&gt;，也可以把其理解为宏观的状态空间。&lt;math&gt;S&lt;/math&gt; 和 &lt;math&gt;A&lt;/math&gt; 之间的Hard <del class="diffchange diffchange-inline">Partition映射关系为：</del>&lt;math&gt;A_i \in S, A_i \neq \empty, A_i \cap A_j = \empty , \forall i, j, \cup_i A_i = S&lt;/math&gt;。这种映射关系是指：&lt;math&gt;A&lt;/math&gt;中的每个元素&lt;math&gt;A_i&lt;/math&gt;都包括了若干个&lt;math&gt;s_i&lt;/math&gt;；&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;之间没有交集，即每个&lt;math&gt;s_i&lt;/math&gt;不会同时属于&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;；&lt;math&gt;S&lt;/math&gt;中的每个元素必须属于某个&lt;math&gt;A&lt;/math&gt;的元素，即&lt;math&gt;A&lt;/math&gt;覆盖了&lt;math&gt;S&lt;/math&gt;。</div></td><td class="diff-marker">+</td><td style="color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #a3d3ff; vertical-align: top; white-space: pre-wrap;"><div>给定一个任意state partition &lt;math&gt;A=\{A_1, A_2, ... ,A_r\}&lt;/math&gt;，也可以把其理解为宏观的状态空间。&lt;math&gt;S&lt;/math&gt; 和 &lt;math&gt;A&lt;/math&gt; 之间的Hard <ins class="diffchange diffchange-inline">Partition映射关系&lt;math&gt;\Phi:S \rightarrow A&lt;/math&gt;为：</ins>&lt;math&gt;A_i \in S, A_i \neq \empty, A_i \cap A_j = \empty , \forall i, j, \cup_i A_i = S&lt;/math&gt;。这种映射关系是指：&lt;math&gt;A&lt;/math&gt;中的每个元素&lt;math&gt;A_i&lt;/math&gt;都包括了若干个&lt;math&gt;s_i&lt;/math&gt;；&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;之间没有交集，即每个&lt;math&gt;s_i&lt;/math&gt;不会同时属于&lt;math&gt;A_i&lt;/math&gt;和&lt;math&gt;A_j&lt;/math&gt;；&lt;math&gt;S&lt;/math&gt;中的每个元素必须属于某个&lt;math&gt;A&lt;/math&gt;的元素，即&lt;math&gt;A&lt;/math&gt;覆盖了&lt;math&gt;S&lt;/math&gt;。</div></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"></td></tr>
<tr><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td><td class="diff-marker"> </td><td style="background-color: #f8f9fa; color: #202122; font-size: 88%; border-style: solid; border-width: 1px 1px 1px 4px; border-radius: 0.33em; border-color: #eaecf0; vertical-align: top; white-space: pre-wrap;"><div>对于任意state partition &lt;math&gt;A&lt;/math&gt;，我们能够定义一个lumped process，即把微观的动力学轨迹&lt;math&gt;s^{(t)}&lt;/math&gt;投影到&lt;math&gt;A&lt;/math&gt;的空间上。</div></td></tr>

<!-- diff cache key wiki:diff::1.12:old-40135:rev-40136 -->
</table>

